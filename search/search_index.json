{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MINDCRAFT WRO Future Engineers team","text":"<p>This repository provides information and knowledge regarding the ongoing progress, evolution, and development of our self-driving robot vehicle, which was created and coded by us, Salmane Derdeb,  Taha TAIDI LAAMIRI and Mortada TAIDI LAAMIRI as participants in the Future Engineers 2024 division of the World Robot Olympiad (WRO).</p>"},{"location":"#world-robot-olympiad-wro","title":"World Robot Olympiad (WRO)","text":"<p>The World Robot Olympiad (WRO) is a prestigious international robotics competition that ignites the imaginations of students worldwide. It challenges participants to showcase their creativity, problem-solving skills, and technical prowess in designing and programming robots for a variety of tasks and challenges.</p> <p>One of the most dynamic categories within WRO is the Future Engineers category. Here, participants are tasked with developing innovative solutions to real-world problems using robotics and automation. This category serves as a breeding ground for future innovators, encouraging students to think critically and creatively, laying the groundwork for a new generation of engineers and technologists.</p> <p>This year, the Future Engineers category presents an exciting challenge: creating a self-driving car. This challenge pushes participants to explore the cutting edge of robotics, adding layers of complexity and innovation to an already thrilling competition.</p> <p>Watch the challenge explanation video</p>"},{"location":"#content","title":"Content","text":"<ul> <li><code>Models</code>: Contains files for models used by 3D printers, laser cutting machines, and CNC machines to produce the vehicle elements. If not needed, this directory can be removed.</li> <li><code>docs</code>: Contains files for models used by 3D printers, laser cutting machines, and CNC machines to produce the vehicle elements. If not needed, this directory can be removed.</li> <li><code>images</code>: Contains files for models used by 3D printers, laser cutting machines, and CNC machines to produce the vehicle elements. If not needed, this directory can be removed.</li> <li><code>other</code>: Contains additional files that can help understand how to prepare the vehicle for the competition, such as documentation on connecting to a SBC/SBM, uploading files, datasets, hardware specifications, and communication protocols descriptions. If not needed, this directory can be removed.</li> <li><code>schemes ( source code )</code>: Contains one or several schematic diagrams (JPEG, PNG, or PDF) illustrating all electromechanical components used in the vehicle, including electronic components and motors, and how they connect to each other.</li> <li><code>src</code>: Contains the control software code for all components programmed to participate in the competition.</li> <li><code>t-photos</code>: Contains 2 photos of the team, including an official one and a funny photo with all team members.</li> <li><code>v-photos</code>: Contains 6 photos of the vehicle, showcasing it from every side as well as from the top and bottom.</li> <li><code>videos</code>: Contains a <code>video.md</code> file with a link to a video demonstrating the vehicle's driving capabilities.</li> </ul>"},{"location":"#wro-future-engineers-competition","title":"WRO Future Engineers Competition","text":"1.Mobility Management Mobility management discussion should cover how the vehicle movements are managed. What motors are selected, how they are selected and implemented. A brief discussion regarding the vehicle chassis design /selection can be provided as well as the mounting of all components to the vehicle chassis/structure. The discussion may include engineering principles such as speed, torque, power etc. usage. Building or assembly instructions can be provided together with 3D CAD files to 3D print parts. Robot Parts &amp; Design Power System Sensing Units Steering System 2.Power and Sense Management Power and Sense management discussion should cover the power source for the vehicle as well as the sensors required to provide the vehicle with information to negotiate the different challenges. The discussion can include the reasons for selecting various sensors and how they are being used on the vehicle together with power consumption. The discussion could include a wiring diagram with BOM for the vehicle that includes all aspects of professional wiring diagrams. Bill of Materials (BOM) Schematics 3.Obstacle Management Obstacle management discussion should include the strategy for the vehicle to negotiate the obstacle course for all the challenges. This could include flow diagrams, pseudo code and source code with detailed comments. Strategy Arduino Functions Open challenge Dashboard Visualisation Map randomizer &amp; score calculator 4.Pictures \u2013 Team and Vehicle Pictures of the team and robot must be provided. The pictures of the robot must cover all sides of the robot, must be clear, in focus and show aspects of the mobility, power and sense, and obstacle management. Reference in the discussion sections 1, 2 and 3 can be made to these pictures. Team photo is necessary for judges to relate and identify the team during the local and international competitions. Vehicle Photos Team Members &amp; Pictures 5.Performance Videos The performance videos must demonstrate the performance of the vehicle from start to finish for each challenge. The videos could include an overlay of commentary, titles or animations. The video could also include aspects of section 1, 2 or 3. Demonstration Videos Youtube Channel 6.GitHub Utilization Git and GitHub are available for opensource project management and file version control. As part of the design and development process, teams must use this platform to document their progress, coding development and share files. Judging the platform will include how complete the information provided is, how information is structured and how often commits were done. Teams can use this platform to provide additional information on their engineering design and coding of their vehicle as well. Repository Link 7.Engineering Factor Own Design and manufacturing of vehicle and components, with off the shelf electrical components, such as motors and sensors. Design Description"},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#tags","title":"Tags","text":"<p>My tags</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"docsfile/docs/","title":"Future Engineers Map Randomizer and Score Calculator","text":"<p>This project provides an interactive web-based tool for the WRO Future Engineers competition. It combines a map randomizer and a score calculator, allowing participants to simulate various configurations of map elements and assess their robot's performance effectively.</p>"},{"location":"docsfile/docs/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Features</li> <li>Getting Started</li> <li>Prerequisites</li> <li>Installation</li> <li>Creating the Project</li> <li>Step 1: Setting Up the HTML Structure</li> <li>Step 2: Styling the Application</li> <li>Step 3: Adding JavaScript Logic<ul> <li>Drawing the Map</li> <li>Randomization Logic</li> <li>Chrono Functionality</li> </ul> </li> <li>Step 4: Testing the Application</li> <li>Code Explanation</li> <li>HTML (index.html)</li> <li>CSS (style.css)</li> <li>JavaScript (script.js)</li> <li>Contributing</li> <li>License</li> </ul>"},{"location":"docsfile/docs/#features","title":"Features","text":"<ul> <li> <p>Map Randomizer: Automatically generates randomized layouts for obstacles and scoring zones.</p> </li> <li> <p>Score Calculator: Quickly calculates scores based on robot interactions with the map elements.</p> </li> <li> <p>Chrono Timer: Tracks the time taken for the robot to complete the course.</p> </li> <li> <p>Responsive Design: Built using HTML, CSS, and JavaScript.</p> </li> <li> <p>User-Friendly Interface: Intuitive design for easy navigation.</p> </li> </ul>"},{"location":"docsfile/docs/#getting-started","title":"Getting Started","text":""},{"location":"docsfile/docs/#prerequisites","title":"Prerequisites","text":"<p>To run this project, ensure you have a modern web browser installed, such as:</p> <ul> <li>Google Chrome</li> <li>Mozilla Firefox</li> <li>Apple Safari</li> <li>Microsoft Edge</li> </ul>"},{"location":"docsfile/docs/#installation","title":"Installation","text":"<ol> <li>Download the Repository: Clone or download the repository to your local machine.</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/WRO-FE-2024-Mindcraft-International.git\n</code></pre> <p>2 - Open the Project: Navigate to the project folder and open the <code>index.html</code> file in your web browser.</p>"},{"location":"docsfile/docs/#creating-the-project","title":"Creating the Project","text":""},{"location":"docsfile/docs/#step-1-setting-up-the-html-structure","title":"Step 1: Setting Up the HTML Structure","text":"<ol> <li>Create an index.html File: Start by creating an HTML file. This will be the main structure of your web application.</li> <li>Add Basic HTML Structure: Inside the <code>index.html</code>, include the basic HTML template and a title for your application. Use the following template:</li> </ol> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;link rel=\"stylesheet\" href=\"style.css\"&gt;\n    &lt;title&gt;Future Engineers Map Randomizer&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Future Engineers Map Randomizer &amp; Score Calculator&lt;/h1&gt;\n    &lt;button id=\"randomizeBtn\"&gt;Randomize Map&lt;/button&gt;\n    &lt;div id=\"mapDisplay\"&gt;&lt;/div&gt;\n\n    &lt;h2&gt;Score Calculation&lt;/h2&gt;\n    &lt;label for=\"obstaclesAvoided\"&gt;Obstacles Avoided:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"obstaclesAvoided\" placeholder=\"Enter number\"&gt;\n    &lt;label for=\"pointsFromZones\"&gt;Points from Scoring Zones:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"pointsFromZones\" placeholder=\"Enter points\"&gt;\n    &lt;button id=\"calculateBtn\"&gt;Calculate Score&lt;/button&gt;\n    &lt;p id=\"result\"&gt;&lt;/p&gt;\n\n    &lt;h2&gt;Chrono&lt;/h2&gt;\n    &lt;button id=\"startChrono\"&gt;Start Timer&lt;/button&gt;\n    &lt;button id=\"stopChrono\"&gt;Stop Timer&lt;/button&gt;\n    &lt;p id=\"chronoDisplay\"&gt;Time: 0s&lt;/p&gt;\n\n    &lt;script src=\"script.js\"&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"docsfile/docs/#step-2-styling-the-application","title":"Step 2: Styling the Application","text":"<ol> <li>Create a style.css File: Create a CSS file in the project folder. This will control the visual appearance of your application.</li> <li>Add Basic Styles: Use the following CSS code to provide basic styling for your layout. Customize as needed:</li> </ol> <pre><code>body {\n    font-family: Arial, sans-serif;\n    text-align: center;\n    background-color: #f4f4f4;\n}\n\nh1 {\n    color: #333;\n}\n\nbutton {\n    padding: 10px 15px;\n    font-size: 16px;\n    margin: 10px;\n    cursor: pointer;\n}\n\ninput {\n    padding: 5px;\n    margin: 10px;\n    width: 50px;\n}\n</code></pre>"},{"location":"docsfile/docs/#step-3-adding-javascript-logic","title":"Step 3: Adding JavaScript Logic","text":"<ol> <li>Create a script.js File: Create a JavaScript file in your project folder. This will contain the logic for randomization, map drawing, and timer functionality.</li> <li>Add Event Listeners: Use the following code to handle user interactions such as randomizing the map, calculating the score, and starting/stopping the timer:</li> </ol> <pre><code>let timerInterval;\nlet seconds = 0;\n\ndocument.getElementById('randomizeBtn').addEventListener('click', function() {\n    const mapDisplay = document.getElementById('mapDisplay');\n    const randomMap = generateRandomMap();\n    mapDisplay.innerHTML = randomMap;\n});\n\ndocument.getElementById('calculateBtn').addEventListener('click', function() {\n    const obstaclesAvoided = document.getElementById('obstaclesAvoided').value;\n    const pointsFromZones = document.getElementById('pointsFromZones').value;\n\n    const totalScore = calculateScore(obstaclesAvoided, pointsFromZones);\n    document.getElementById('result').innerText = `Total Score: ${totalScore}`;\n});\n\ndocument.getElementById('startChrono').addEventListener('click', function() {\n    startTimer();\n});\n\ndocument.getElementById('stopChrono').addEventListener('click', function() {\n    stopTimer();\n});\n\nfunction generateRandomMap() {\n    const obstacles = ['Wall', 'Pit', 'Ramp'];\n    const scoringZones = ['Zone A', 'Zone B', 'Zone C'];\n    let mapLayout = '';\n\n    for (let i = 0; i &lt; 5; i++) {\n        const randomObstacle = obstacles[Math.floor(Math.random() * obstacles.length)];\n        const randomZone = scoringZones[Math.floor(Math.random() * scoringZones.length)];\n        mapLayout += `&lt;div&gt;${randomObstacle} | ${randomZone}&lt;/div&gt;`;\n    }\n\n    return mapLayout;\n}\n\nfunction calculateScore(obstacles, points) {\n    const pointsForObstacles = 10; // Example points for each obstacle avoided\n    return parseInt(points) + (pointsForObstacles * parseInt(obstacles));\n}\n\nfunction startTimer() {\n    timerInterval = setInterval(() =&gt; {\n        seconds++;\n        document.getElementById('chronoDisplay').innerText = `Time: ${seconds}s`;\n    }, 1000);\n}\n\nfunction stopTimer() {\n    clearInterval(timerInterval);\n}\n</code></pre>"},{"location":"docsfile/docs/#drawing-the-map","title":"Drawing the Map","text":"<p>In the <code>generateRandomMap()</code> function, we create a simple representation of the map by randomly selecting obstacles and scoring zones. The function constructs a string that includes random combinations of these elements, which is then displayed in the <code>mapDisplay</code> div.</p>"},{"location":"docsfile/docs/#randomization-logic","title":"Randomization Logic","text":"<p>The randomization works by selecting a random item from arrays of predefined obstacles and scoring zones. The code uses <code>Math.random()</code> and <code>Math.floor()</code> to ensure that a valid index is chosen each time a random element is requested.</p>"},{"location":"docsfile/docs/#chrono-functionality","title":"Chrono Functionality","text":"<p>The chrono (timer) functionality is implemented with two main functions: <code>startTimer()</code> and <code>stopTimer()</code>. The <code>startTimer()</code> function sets an interval that increments a seconds counter every second, updating the display accordingly. The <code>stopTimer()</code> function clears this interval, effectively stopping the timer.</p>"},{"location":"docsfile/docs/#step-4-testing-the-application","title":"Step 4: Testing the Application","text":"<ol> <li>Open the Application: After setting up the files, open <code>index.html</code> in your web browser to see the application in action.</li> <li>Interact with the Application: Click the \"Randomize Map\" button to generate a new map layout, enter data in the input fields, calculate the score, and start/stop the timer to ensure everything works as expected.</li> </ol>"},{"location":"docsfile/docs/#code-explanation","title":"Code Explanation","text":""},{"location":"docsfile/docs/#html-indexhtml","title":"HTML (index.html)","text":"<p>The HTML file contains the basic structure for the application. It includes buttons for randomizing the map, calculating the score, and managing the timer, as well as input fields for user interaction.</p>"},{"location":"docsfile/docs/#css-stylecss","title":"CSS (style.css)","text":"<p>The CSS file provides styles for the application. You can adjust colors, fonts, and layout to customize the appearance further.</p>"},{"location":"docsfile/docs/#javascript-scriptjs","title":"JavaScript (script.js)","text":"<p>The JavaScript file handles the logic for randomization, score calculation, and timer functionality. It listens for user actions and performs the corresponding operations, updating the displayed results.</p>"},{"location":"docsfile/docs/#website-preview","title":"Website Preview","text":"<p>Access the Website Explore the interactive tool by visiting the following link:</p> <p>https://dextertaha.github.io/WRO-FE-2024-Mindcraft-International/</p>"},{"location":"modelsfile/AxleClamp/","title":"Axle-Clamp","text":"Axle Clamp <p>The \"Axle Clamp\" is designed to secure the shaft from the opposite direction of the bearing, providing rotational stability while preventing any axial movement. It features a hole that aligns with a hole in the shaft, allowing it to be fastened securely using a screw and nut. This setup ensures that the shaft rotates freely without shifting along its axis, maintaining precise alignment and reliable rotational performance in the robot's mechanisms.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports None Fan Speed 100%"},{"location":"modelsfile/BackSupportCamera/","title":"Back-Support-Camera","text":"Back Support Camera <p>The \"Back Support Camera\" allows for adjustable camera angling, enabling precise alignment to suit various operational needs. It securely connects to the Connector Support Camera, providing stability while retaining the protective functions of the Front Support Camera. This component ensures the camera is well-supported, safeguarding the sensor and lens, and allowing reliable, customizable positioning for optimal image capture and functionality in the robot\u2019s vision system.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 50% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/BerringSupportFrontBottom/","title":"Berring-Support-Front-Bottom","text":"Berring Support Front Bottom <p>The \"Bearing Support Front Bottom\" is designed to securely hold the bearing and front shaft that support the wheel, facilitating smooth rotation. This support enables the front steering wheel to turn freely, enhancing maneuverability and stability by reducing friction in the wheel\u2019s rotation. Its structure is critical for allowing passive steering, ensuring the front wheel follows the motion of the robot seamlessly, optimizing control and alignment.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 50% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/BerringSupportFrontTop/","title":"Berring-Support-Front-Top","text":"Berring Support Front Top <p>The \"Bearing Support Front Top\" functions similarly to the Bearing Support Front Bottom by holding the bearing and front shaft to enable smooth, free rotation of the front wheel. Additionally, it connects to the steering rack, transmitting the servo motor\u2019s rotation directly to the wheels. This design provides controlled steering, allowing precise directional adjustments while maintaining stability. It plays a crucial role in the robot\u2019s maneuverability, linking motorized steering with the passive wheel rotation system.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 50% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/BigGear/","title":"Big-Gear","text":"Big Gear <p>The \"Big Gear\" features a depth of 15 mm, 30 teeth, a module of 1.65 mm, a pitch circle diameter of 49.5 mm, a pressure angle of 20 degrees, and a root fillet of 1/3. This gear connects to the motor through a meshing gear and has an internal hole that attaches to the differential system. It effectively transmits the motor\u2019s rotational power through the differential, ensuring smooth power delivery to the wheels for consistent movement and control.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/ConectorSupportCamera/","title":"Conector-Support-Camera","text":"Conector Support Camera <p>The \"Connector Support Camera\" is responsible for securely attaching the camera to the robot, providing stability and durability for the camera assembly. It not only connects and supports the camera but also serves as a convenient handle for carrying the robot, as it is the highest point on the structure. This dual functionality enhances usability, ensuring the camera remains stable while making the robot easy to transport.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 80% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/FrontSupportCamera/","title":"Front-Support-Camera","text":"Front Support Camera <p>The \"Front Support Camera\" is designed to securely hold the camera in place, protecting its sensor and lens from potential impacts. This component ensures the camera remains stable during operation and is firmly attached to the Back Support Camera for added support. By safeguarding the camera\u2019s essential parts, the Front Support Camera maintains optimal positioning, enabling consistent and reliable image capture essential for the robot\u2019s vision-based functions.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 250 Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/SteeringConector/","title":"Steering-Conector","text":"Steering Conector <p>The \"Steering Connector\" securely attaches the Steering Rack to the servo motor, transmitting the servo\u2019s movements directly to the rack. This component is essential for ensuring that the rotational input from the servo motor translates accurately into steering adjustments. By providing a stable and reliable connection, the Steering Connector enables precise control over the robot\u2019s directional movements, enhancing its ability to navigate and respond to steering commands smoothly.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/SteeringRack/","title":"Steering-Rack","text":"Steering Rack <p>The \"Steering Rack\" is responsible for connecting and transmitting rotational motion from the servo motor to the Bearing Support Front Top, functioning similarly to a four-bar linkage system. This setup enables precise control over the front wheel\u2019s direction, allowing smooth and accurate steering adjustments. The Steering Rack\u2019s design enhances maneuverability by directly translating servo movements into wheel alignment changes, ensuring the robot can navigate turns and complex paths effectively.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports None Fan Speed 100%"},{"location":"modelsfile/frontshaft/","title":"front-shaft","text":"Front Shaft <p>The \"Front Shaft\" is designed to securely hold the wheel in place using screws and nuts, allowing it to rotate freely and follow the movement of the motor-driven rear wheels. Unlike the rear shaft, the front shaft operates independently of any motor connection, enabling smooth, passive movement. This setup provides stability and reduces drag, allowing the robot to navigate efficiently while maintaining alignment with the rear-driven wheels.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/gear/","title":"Gear","text":"Gear <p>The \"Gear\" is responsible for transmitting rotational motion from the motor to the Big Gear, enabling efficient power transfer within the system. This gear has a depth of 15 mm, 15 teeth, a module of 1.65 mm, a pitch circle diameter of 24.75 mm, a pressure angle of 20 degrees, and a root fillet of 1/3, as shown in the image. Its precise specifications ensure smooth engagement with the Big Gear, maintaining reliable motion transmission.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports None Fan Speed 100%"},{"location":"modelsfile/longshaft/","title":"long-shaft","text":"Long Shaft <p>The \"Long Shaft\" is designed to securely connect the wheels using screws and nuts, transmitting rotational power from the motor directly to the wheels. It also features compatibility with the LEGO gear on the differential system, enabling smooth integration and effective power transfer. Constructed with high strength and durability, this shaft endures intensive loads, ensuring reliable performance and stability during maneuvers. Its robust design is crucial for efficient and consistent movement in competition settings.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/models/","title":"WRO Future Engineers Robot - Models","text":"<p>This section covers the CAD modeling and manufacturing process behind the development of our robot for the WRO Future Engineers competition, explaining our design tools, choices, and manufacturing techniques. The following highlights the key decisions in our process and why they benefit the project.</p>"},{"location":"modelsfile/models/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Design Considerations Before CAD Modeling</li> <li>Key Requirements</li> <li>Study and Planning</li> <li>Initial Robot Design and Iterations</li> <li>National Competition: LEGO Robot</li> <li>First Version: Oversized DIY Robot</li> <li>Second Version: Lack of Differential System</li> <li>Third Version: Final Optimized Robot</li> <li>3D CAD Modeling - Onshape</li> <li>Why We Chose Onshape</li> <li>Video of Onshape Demonstration</li> <li>Screenshots of Our Robot 3D Model in Onshape</li> <li>Other CAD Options Considered</li> <li>Onshape Advantages</li> <li>Learning Onshape</li> <li>3D Printing</li> <li>Why We Chose 3D Printing</li> <li>Printer of Choice: Creality K1 Max</li> <li>3D Printed Robot Parts</li> <li>Video of Printing a Part</li> <li>Why We Didn't Choose Laser Cutting or CNC Engraving</li> <li>Robot</li> <li>Robot Assembly</li> <li>Power System</li> <li>Steering System</li> <li>Robot Parts Details</li> <li>Conclusion</li> </ol>"},{"location":"modelsfile/models/#design-considerations-before-cad-modeling","title":"Design Considerations Before CAD Modeling","text":"<p>Before we began the CAD modeling process, we conducted a thorough study to establish the key requirements and considerations for our robot design. Our primary goal was to create a robot that is efficient, reliable, and optimized for the competition's challenges. The following points outline the main factors we considered:</p>"},{"location":"modelsfile/models/#key-requirements","title":"Key Requirements","text":"<ul> <li>Compact Size: Our strategy required the robot to be smaller than a 20cm cube to navigate efficiently through the competition environment.</li> <li>Turning Radius: The robot must be able to turn within an outside circle of maximum 40cm, enabling it to maneuver in tight spaces.</li> <li>Stability: A low center of gravity was essential to ensure the robot's stability during movement and operations.</li> <li>Weight Distribution: Equal weight distribution across the robot prevents tipping and improves handling.</li> <li>Traction: High friction on traction wheels was necessary to prevent slipping and to provide better control.</li> <li>Assembly Method: All robot parts should be assembled using screws, nuts, and zip ties\u2014no glue\u2014to allow for easy modifications and repairs.</li> <li>Ease of Modification: The robot should be sturdy yet easy to modify and improve as needed.</li> <li>Lightweight Design: Keeping the robot as lightweight as possible enhances speed and reduces energy consumption.</li> <li>Differential System: Incorporating a differential system allows the robot to turn easily and smoothly.</li> <li>Battery Safety: The battery should be placed in a safe location to avoid damage from bumps or accidents, and to prevent hazards if the battery fails.</li> <li>Component Safety: Critical components should be protected from potential battery issues, such as leaks or explosions.</li> <li>Ease of Reassembly: The robot should be easy to rebuild, with parts designed to assemble in only one way to minimize errors.</li> <li>Availability of Parts: All parts should be commonly available in most markets to allow other teams to rebuild or service the robot if needed.</li> </ul>"},{"location":"modelsfile/models/#study-and-planning","title":"Study and Planning","text":"<p>We meticulously planned the robot's design to meet these requirements. By prioritizing a compact and stable structure, we ensured that the robot could navigate the competition course effectively. The decision to use common assembly methods and readily available parts not only facilitated our building process but also made our design accessible to others.</p>"},{"location":"modelsfile/models/#initial-robot-design-and-iterations","title":"Initial Robot Design and Iterations","text":"<p>Our journey began with initial prototypes and several iterations to refine our robot design. Throughout this process, we learned valuable lessons that informed our final design.</p>"},{"location":"modelsfile/models/#national-competition-lego-robot","title":"National Competition: LEGO Robot","text":"<p>We participated in the national competition with a robot constructed using LEGO components due to their ease of use and availability. However, this version had several issues:</p> <ul> <li>Size and Speed Issues: The robot was too big and slow, exceeding the size limitations we had set and lacking the required speed.</li> <li>Obstacle Challenges: We couldn't manage to successfully complete the obstacle challenge and parking, which are critical parts of the competition.</li> <li>Structural Limitations: LEGO components did not provide the sturdiness and customization required for the competition's demands.</li> </ul> <p>Image of LEGO Robot Used in National Competition:</p> <p>LEGO Robot</p>"},{"location":"modelsfile/models/#first-version-oversized-diy-robot","title":"First Version: Oversized DIY Robot","text":"<p>After qualifying for the international stage, we decided to build a 100% DIY robot, making all the mechanics and body ourselves while purchasing only the electronics. Our first DIY version had the following issues:</p> <ul> <li>Size Issue: The robot was still too big, not meeting our compact size requirement of fitting within a 20cm cube.</li> <li>Weight Problems: The larger size contributed to increased weight, affecting speed and maneuverability.</li> <li>Inefficient Design: The oversized structure made it difficult to navigate the course effectively.</li> </ul> <p>Link of First DIY Robot Version:</p> <p>First DIY Robot</p>"},{"location":"modelsfile/models/#second-version-lack-of-differential-system","title":"Second Version: Lack of Differential System","text":"<p>In the second iteration of our DIY robot, we attempted to reduce the size and weight but encountered new challenges:</p> <ul> <li>No Differential System: The robot lacked a differential system, making turning difficult and inefficient.</li> <li>Poor Maneuverability: The robot would drift a lot and took 150cm to complete a full turn, which is unacceptable for tight course navigation.</li> <li>Inefficient Turning Radius: The large turning radius prevented the robot from handling obstacles and precise movements required in the competition.</li> </ul> <p>Link of Second DIY Robot Version:</p> <p>Second DIY Robot</p>"},{"location":"modelsfile/models/#third-version-final-optimized-robot","title":"Third Version: Final Optimized Robot","text":"<p>For the third version, we made significant changes to address the previous shortcomings:</p> <ul> <li>Incorporation of Differential System: We added a differential system to allow smooth and efficient turning.</li> <li> <p>Hardware Upgrade: We switched from using the NVIDIA Jetson Nano to the Raspberry Pi 4 Model B, which provided:</p> </li> <li> <p>Improved Compatibility: Better compatibility with our control systems and peripherals.</p> </li> <li>Weight Reduction: The Raspberry Pi is lighter, contributing to our goal of a lightweight robot.</li> <li> <p>Energy Efficiency: Lower power consumption helped manage the robot's energy requirements.</p> </li> <li> <p>Optimized Design: The robot now fits within the 20cm cube constraint, has a low center of gravity, and features equal weight distribution.</p> </li> <li>Enhanced Maneuverability: With the differential system, the robot can turn efficiently within the required 40cm outside circle.</li> <li>Sturdy and Modular Assembly: All parts are assembled using screws, nuts, and zip ties\u2014no glue\u2014making the robot sturdy yet easy to modify and improve.</li> <li>Safety Features: The battery is placed in a safe location to avoid damage from bumps or accidents, and critical components are protected from potential battery issues.</li> </ul> <p>Link of Third DIY Robot Version:</p> <p>Third DIY Robot</p> <p>This final version solved all the problems encountered in previous iterations, resulting in a robot that is compact, efficient, and competition-ready.</p>"},{"location":"modelsfile/models/#3d-cad-modeling-onshape","title":"3D CAD Modeling - Onshape","text":"<p>To design and develop the robot, we used Onshape, a cloud-based CAD tool that allows for efficient collaboration and design flexibility. We had various options for CAD software, such as Fusion 360 and CATIA, but we ultimately chose Onshape for several reasons:</p>"},{"location":"modelsfile/models/#why-we-chose-onshape","title":"Why We Chose Onshape","text":"<ul> <li>Cloud-Based: Onshape operates entirely in the cloud, allowing our team to collaborate from any location. This was essential since team members were working from different places.</li> <li>Collaborative Design: Multiple team members can work on the same design simultaneously, ensuring faster iterations and feedback loops.</li> <li>Free for Educational Use: Being students representing Morocco, Onshape\u2019s free educational plan provided us with full access to powerful design tools without extra costs.</li> <li>No Hardware Constraints: Onshape runs in a web browser, meaning we didn\u2019t need high-end computers or complex software installations. This allowed everyone on the team to contribute regardless of their hardware limitations.</li> </ul> <p>You can learn more about Onshape here: Onshape Website</p>"},{"location":"modelsfile/models/#video-of-onshape-demonstration","title":"Video of Onshape Demonstration","text":""},{"location":"modelsfile/models/#screenshots-of-our-robot-3d-model-in-onshape","title":"Screenshots of Our Robot 3D Model in Onshape","text":""},{"location":"modelsfile/models/#other-cad-options-considered","title":"Other CAD Options Considered","text":"<ul> <li>Fusion 360: Hybrid cloud solution, limited collaboration, and high costs.</li> <li>CATIA: Too complex and expensive for our needs.</li> </ul>"},{"location":"modelsfile/models/#onshape-advantages","title":"Onshape Advantages","text":"<ul> <li>Real-Time Collaboration: Multiple people can work on the design at the same time, accelerating the design process.</li> <li>Accessible Anywhere: Since it\u2019s cloud-based, we could work on designs from any device with an internet connection.</li> <li>Powerful CAD Tools: Despite being browser-based, Onshape provides all the advanced CAD features we needed to design complex mechanical components for our robot.</li> <li>Version Control: We could easily track changes, revert to previous versions, and work on multiple iterations without losing progress.</li> </ul>"},{"location":"modelsfile/models/#learning-onshape","title":"Learning Onshape","text":"<p>We learned how to use Onshape through resources from the official Onshape website and a helpful playlist on YouTube.</p> <ul> <li>Onshape Official Website</li> <li>Onshape YouTube Playlist</li> </ul>"},{"location":"modelsfile/models/#3d-printing","title":"3D Printing","text":"<p>Once our designs were finalized in Onshape, we needed to choose a manufacturing method. We considered several techniques like laser cutting, CNC engraving, and 3D printing, but we ultimately decided to use 3D printing due to its flexibility and ability to produce complex parts for our robot.</p>"},{"location":"modelsfile/models/#why-we-chose-3d-printing","title":"Why We Chose 3D Printing","text":"<ul> <li>Complex Geometries: 3D printing allowed us to create complex and custom geometries that are difficult to achieve with laser cutting or CNC engraving.</li> <li>Rapid Prototyping: We could quickly print and test various parts, allowing us to make fast iterations on our robot design.</li> <li>Cost-Effective: 3D printing is often more affordable for one-off parts or prototypes compared to CNC engraving or laser cutting, which require more setup and material waste.</li> <li>Less Material Waste: 3D printing only uses the material needed for the part, reducing waste and lowering costs.</li> </ul>"},{"location":"modelsfile/models/#printer-of-choice-creality-k1-max","title":"Printer of Choice: Creality K1 Max","text":"<p>We selected the Creality K1 Max 3D printer for manufacturing our robot parts. This printer has several key advantages:</p> <ul> <li>Large Build Volume: The K1 Max provides a large build area, allowing us to print large components of the robot in a single go without having to divide them into smaller parts.</li> <li>High Speed: With fast print speeds, we were able to print our parts in a short amount of time, keeping up with the rapid pace of our project.</li> <li>Precision: The Creality K1 Max delivers high accuracy and detail in its prints, ensuring that our robot's mechanical parts fit together perfectly.</li> <li>Ease of Use: The printer is easy to set up and use, even for students, making it an ideal choice for quick prototyping.</li> </ul> <p>Learn more about the Creality K1 Max here: Creality K1 Max Printer</p>"},{"location":"modelsfile/models/#3d-printed-robot-parts","title":"3D Printed Robot Parts","text":""},{"location":"modelsfile/models/#video-of-printing-a-part","title":"Video of Printing a Part","text":"<p>This video was made by us while printing the robot base of our robot.</p>"},{"location":"modelsfile/models/#why-we-didnt-choose-laser-cutting-or-cnc-engraving","title":"Why We Didn't Choose Laser Cutting or CNC Engraving","text":"<ul> <li>Laser Cutting: While laser cutting is great for creating flat, 2D parts, it is limited in producing complex 3D shapes and detailed mechanical components.</li> <li>CNC Engraving: CNC is excellent for metal and wood parts but involves more setup time and higher costs, especially for custom parts. It also generates more material waste, making it less ideal for our project, which requires many iterations.</li> </ul>"},{"location":"modelsfile/models/#advantages-of-3d-printing","title":"Advantages of 3D Printing","text":"<ul> <li>Customization: We can easily make modifications to the design and print new parts within hours.</li> <li>Quick Turnaround: 3D printing enabled us to quickly prototype, test, and refine parts, significantly reducing development time.</li> <li>Sustainable: With 3D printing, there\u2019s less waste of materials, aligning with our goal of sustainability for this project.</li> </ul>"},{"location":"modelsfile/models/#robot","title":"Robot","text":""},{"location":"modelsfile/models/#robot-assembly","title":"Robot Assembly","text":"Robot Robot Dimensions Robot Assembly Robot View"},{"location":"modelsfile/models/#power-system","title":"Power System","text":"Power System Power System Assembly Power System View"},{"location":"modelsfile/models/#steering-system","title":"Steering System","text":"Steering System Steering System Assembly Steering System View"},{"location":"modelsfile/models/#robot-parts-details","title":"Robot Parts Details","text":"Part Name Image 3D File Link 0x00- Robot Base Part Details 0x01- Second Layer Part Details 0x02- Third Layer Part Details 0x03- Short Shaft Part Details 0x04- Long Shaft Part Details 0x05- Front Short Shaft Part Details 0x06- Bearing Support Front Bottom Part Details 0x07- Bearing Support Front Top Part Details 0x08- Steering Rack Part Details 0x09- Steering Connector Part Details 0x10- Axle Clamp Part Details 0x11- Big Gear Part Details 0x12- Gear Part Details 0x13- Front Support Camera Part Details 0x14- Back Support Camera Part Details 0x15- Connector Support Camera Part Details"},{"location":"modelsfile/models/#conclusion","title":"Conclusion","text":"<p>For our WRO Future Engineers robot project, using Onshape for CAD modeling and the Creality K1 Max for 3D printing has been a critical part of our design and manufacturing process. These tools allowed us to work collaboratively, iterate quickly, and produce complex parts efficiently, all while staying within the constraints of an educational project.</p> <p>Thank you for following our journey as we design a cutting-edge robot to represent Morocco on the global stage at the World Robot Olympiad!</p> <p>For more information and to follow our progress, check out our Project Link.</p>"},{"location":"modelsfile/robotbase/","title":"robot-base","text":"Robot Base <p>The \"Robot Base\" is the foundational structure of the WRO competition robot, meticulously designed to support the steering and driving mechanisms. Built with reinforced strength, it securely holds four bearings and provides a safe compartment for the LiPo battery, shielding it from impact. A dedicated gap accommodates the differential system, enhancing maneuverability for tight turns. The base also includes mounts for four Distance Time-of-Flight (DTOF) sensors, allowing precise obstacle detection and navigation, along with a LiPo test indicator sensor for real-time battery monitoring. For neat wiring, the base is equipped with cable management holes and guides, ensuring organized and secure connections that prevent accidental disconnections. This combination of durability, stability, and thoughtful functionality makes the Robot Base essential for competitive reliability and ease of maintenance.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 60% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports Yes Fan Speed 100%"},{"location":"modelsfile/secondlayer/","title":"second-layer","text":"Second Layer <p>The \"Second Layer\" is designed to overlay and secure the Robot Base, providing additional stability and structure. It holds the bearings and wheels firmly, ensuring smooth movement and alignment. This layer also mounts the motor, supporting the robot\u2019s driving mechanism, and houses the 5V converter for consistent power supply. Laddered holes are included for standoffs, allowing easy assembly and modular adjustments. This structural layer enhances durability while organizing key components securely.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 40% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/shortshaft/","title":"short-shaft","text":"Short Shaft <p>The \"Short Shaft\" is designed to securely connect the wheels using screws and nuts, transmitting rotational power from the motor directly to the wheels. It also features compatibility with the LEGO gear on the differential system, enabling smooth integration and effective power transfer. Constructed with high strength and durability, this shaft endures intensive loads, ensuring reliable performance and stability during maneuvers. Its robust design is crucial for efficient and consistent movement in competition settings.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 100% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"modelsfile/thirdlayer/","title":"third-layer","text":"Third Layer <p>The \"Third Layer\" is responsible for securely holding all electronics, including the Raspberry Pi, Arduino, switch, start buttons, and motor drive PCB board. Designed with multiple standoff positions and screw holes, it provides a sturdy mounting solution that keeps components organized and protected. This layer optimizes space for electronic integrations, enabling efficient assembly and maintenance. Its thoughtful layout supports easy access to each component, ensuring reliability and durability during competition.</p> Drawing PNG: <p> </p> STL File Link: <p>You can view the 3D model directly from the repository by clicking this link.</p> Onshape File Link: <p>You can view the 3D model on Onshape by clicking this link.</p> Video Printing: <p> </p> <p>Click the image above to watch the video.</p> Printing Parameters: Parameter Value Material PLA Layer Height 0.08 mm Infill Density 20% Print Speed 200 mm/s Nozzle Size 0.4 mm Bed Temperature 60\u00b0C Print Temperature 200\u00b0C Supports yes Fan Speed 100%"},{"location":"otherfile/BOM/","title":"BOM","text":"Bill of Materials Code Name Datasheet Setup 3D Model Description Image 0x00 Raspberry Pi 4B Datasheet Setup 3D Model Main computing unit 0x01 Arduino NANO Datasheet Setup 3D Model Microcontroller 0x02 LIDAR Datasheet Setup 3D Model Laser Range Sensor 0x03 Distance Sensor VL53L1X Datasheet Setup 3D Model Time-of-Flight Distance Sensor 0x04 GYROSCOPE Sensor MPU6050 Datasheet Setup 3D Model 6-axis Gyroscope and Accelerometer 0x05 Camera Datasheet Setup 3D Model Camera module 0x06 DC Brushed Motor with Encoder Datasheet Setup 3D Model Motor for movement with encoder feedback 0x07 Wheels Datasheet Setup 3D Model Wheels for robot movement 0x08 L298 Motor Driver Datasheet Setup 3D Model Command Motor High Voltage with logic voltage 5v 0x09 Servo motor Metal Gear Box 180\u00b0 Datasheet Setup 3D Model For Robot turning 0x10 5V Power Converter Datasheet Setup 3D Model 5V Power Converter 0x11 Lipo 3S 2200mah 11.1V 50C Datasheet N/A 3D Model Lithium Polymer Battery 0x12 IMAX B6AC V2 Datasheet Setup 3D Model Battery Charger 0x13 7806 Transistor Datasheet N/A 3D Model 6V Voltage Regulator 0x14 Switch High Amper Datasheet N/A 3D Model High Current Switch 0x15 Buzzer Alarm Batterie Lipo Datasheet N/A 3D Model Lipo Battery Alarm 0x16 Servo Tester Datasheet N/A 3D Model Servo Motor Tester 0x17 Servobras Datasheet N/A 3D Model Servo Arm 0x18 SD Card 64GB Datasheet N/A 3D Model 64GB SD Card 0x19 TPLink AC600 Datasheet Setup 3D Model WiFi Adapter"},{"location":"otherfile/PowerSystem/","title":"Power-System","text":""},{"location":"otherfile/PowerSystem/#rear-drive-system-overview","title":"Rear Drive System Overview","text":"<p>The rear-drive system of the robot relies on a horizontally mounted electric motor connected to gear mechanisms. This system converts the motor\u2019s rotational motion into the rotational movement of the rear wheels. The motor is linked to gears that reduce the rotational speed while increasing the torque applied to the wheels, enhancing the robot's ability to move steadily and efficiently.</p> <p>The fundamental equation governing motion transfer is:</p> <pre><code>\u03b8_wheel = T / r\n</code></pre> <p>Where: - \u03b8_wheel represents the angular rotation of the rear wheels. - T is the torque produced by the motor. - r is the radius of the gear connected to the wheel.</p> <p>This system allows the rear wheels to rotate around a horizontal axis, providing smooth movement and sufficient traction to propel the robot forward. The overall movement of the robot is controlled through the mechanical relationship between the motor, gears, and wheels, governed by the equation that relates torque to angular displacement.</p> <p>This system relies on precise dynamic simulation to ensure optimal motion control, ensuring performance efficiency and fast response under various operating conditions.</p>"},{"location":"otherfile/SensingUnits/","title":"Sensing-Units","text":""},{"location":"otherfile/SensingUnits/#sensing-units","title":"Sensing units:","text":"<p>The distance sensors in the robot play a crucial role in enabling it to interact with its environment and avoid obstacles. In this robot, laser-based distance sensors are placed on four sides: front, back, and both sides. These sensors use laser technology to measure the distance to objects. They emit laser beams that reflect when they hit an obstacle, and by calculating the time it takes for the beam to return, the robot can accurately estimate the distance.</p> <p>Having sensors on all four sides provides the robot with 360-degree coverage, giving it a comprehensive \"view\" of its surroundings. The front sensors detect obstacles in the robot\u2019s path, preventing collisions as it moves forward. The rear sensors allow the robot to reverse safely without hitting any objects behind it. The side sensors, on both the left and right, enable the robot to detect obstacles during turns or maneuvers, ensuring smooth and precise movement even in complex environments.</p> <p>The system integrates data from all these sensors to create a complete map of the surrounding environment. Using this information, the robot can make real-time decisions such as avoiding obstacles, selecting the optimal path, or stopping when approaching an unexpected object. These sensors also allow the robot to navigate through complicated routes without the need for direct human control, enhancing its autonomous navigation capabilities.</p> <p>The sensors provide high accuracy thanks to laser technology, which allows reliable distance measurement even at relatively long ranges. This precision improves the robot\u2019s responsiveness, making it capable of reacting quickly to changes in its environment\u2014whether it\u2019s avoiding an approaching person or maneuvering around a sudden obstacle in its path.</p>"},{"location":"otherfile/SensingUnits/#testing-sensors","title":"Testing Sensors:","text":""},{"location":"otherfile/SensingUnits/#gyroscope","title":"Gyroscope:","text":""},{"location":"otherfile/SensingUnits/#temperature-sensor","title":"Temperature Sensor:","text":""},{"location":"otherfile/SettingUpYourRaspberryPi/","title":"Setting-Up-Your-Raspberry-Pi","text":"<p>= Setting Up Your Raspberry Pi</p> <p>== Getting Started with Your Raspberry Pi</p> <p>image::https://img.youtube.com/vi/CQtliTJ41ZE/0.jpg[youtube, link=\"https://www.youtube.com/watch?v=CQtliTJ41ZE\"]</p> <p>To get started with your Raspberry Pi, you'll need the following:</p> <ul> <li>a xref:raspberry-pi.adoc#power-supply[power supply]</li> <li>boot media (e.g., a xref:getting-started.adoc#recommended-sd-cards[microSD card with ample storage and speed])</li> </ul> <p>You can set up your Raspberry Pi as an interactive computer with a desktop or as a headless computer accessible only over the network. To set up headlessly, preconfigure a hostname, user account, network connection, and SSH when installing the operating system.</p> <p>For a direct setup, you\u2019ll need:</p> <ul> <li>Display</li> <li>Cable to connect your Raspberry Pi to your display</li> <li>Keyboard</li> <li>Mouse</li> </ul> <p>== Power Supply</p> <p>Here\u2019s the required USB-PD power mode for various Raspberry Pi models:</p> <p>[%header,cols=\"1,1,1\"] |=== |Model |Recommended Power Supply (voltage/current) |Raspberry Pi Power Supply Link</p> <p>|Raspberry Pi 5 |5V/5A, 5V/3A limits peripherals to 600mA |https://www.raspberrypi.com/products/27w-power-supply/[27W USB-C power supply]</p> <p>|Raspberry Pi 4 Model B |5V/3A |https://www.raspberrypi.com/products/type-c-power-supply/[15W USB-C power supply]</p> <p>|Raspberry Pi 3 (all models) |5V/2.5A |https://www.raspberrypi.com/products/micro-usb-power-supply/[12.5W Micro USB power supply]</p> <p>|Raspberry Pi 2 (all models) |5V/2.5A |https://www.raspberrypi.com/products/micro-usb-power-supply/[12.5W Micro USB power supply]</p> <p>|Raspberry Pi 1 (all models) |5V/2.5A |https://www.raspberrypi.com/products/micro-usb-power-supply/[12.5W Micro USB power supply]</p> <p>|Raspberry Pi Zero (all models) |5V/2.5A |https://www.raspberrypi.com/products/micro-usb-power-supply/[12.5W Micro USB power supply] |===</p> <p>image::images/peripherals/cable-power.png[alt=\"Plugging a power supply into a Raspberry Pi\"]</p> <p>Plug the power supply into the port marked \"POWER IN,\" \"PWR IN,\" or \"PWR\". Be careful to use the correct port, as some models have output USB ports similar to the power port.</p> <p>== Boot Media</p> <p>Raspberry Pi models require external storage, typically a microSD card. Only recent models support booting from USB or network storage.</p> <p>image::images/peripherals/sd-card.png[alt=\"Inserting a microSD card into a Raspberry Pi\"]</p> <p>Recommended SD cards:</p> <ul> <li>Minimum 32GB for Raspberry Pi OS installations</li> <li>Minimum 16GB for Raspberry Pi OS Lite installations</li> <li>Up to 2TB (MBR limit)</li> </ul> <p>Older models and specific ones like Raspberry Pi Zero support only up to 256GB boot partitions.</p> <p>== Keyboard and Mouse</p> <p>You can use any USB port for connecting a wired keyboard and mouse or a USB Bluetooth receiver.</p> <p>image:images/peripherals/cable-key.png[alt=\"Plugging a keyboard into a Raspberry Pi\"] image:images/peripherals/cable-mouse.png[alt=\"Plugging a mouse into a Raspberry Pi\"]</p> <p>== Display Connectivity</p> <p>[%header,cols=\"1,1\"] |=== |Model |Display Outputs</p> <p>|Raspberry Pi 5 |2\u00d7 micro HDMI</p> <p>|Raspberry Pi 4 (all models) |2\u00d7 micro HDMI, audio and composite out via TRRS jack</p> <p>|Raspberry Pi 3 (all models) |HDMI, audio and composite out via TRRS jack</p> <p>|Raspberry Pi 2 (all models) |HDMI, audio and composite out via TRRS jack</p> <p>|Raspberry Pi 1 Model B+ / Model A+ |HDMI, audio and composite out via TRRS jack</p> <p>|Raspberry Pi Zero (all models) |mini HDMI |===</p> <p>Use <code>HDMI0</code> for the primary display if your model has multiple HDMI ports. </p> <p>== Audio Support</p> <p>All Raspberry Pi models with HDMI, micro HDMI, or mini HDMI support audio over HDMI. Models with Bluetooth also support Bluetooth audio, and models with a 3.5mm auxiliary jack (TRRS) support audio output (amplification may be needed).</p> <p>== Networking</p> <p>Models with Wi-Fi and Bluetooth:</p> <ul> <li>Raspberry Pi 5</li> <li>Raspberry Pi 4</li> <li>Raspberry Pi 3B+ / 3</li> <li>Raspberry Pi Zero W / Zero 2 W</li> </ul> <p>For models without Ethernet, use a USB-to-Ethernet adapter.</p> <p>image::images/peripherals/cable-net.png[alt=\"Plugging an Ethernet cable into a Raspberry Pi\"]</p>"},{"location":"otherfile/SteeringSystem/","title":"Steering-System","text":""},{"location":"otherfile/SteeringSystem/#ackermann-steering-structure-and-calculation","title":"Ackermann Steering Structure and Calculation","text":"<p>The Ackermann steering geometry is designed to ensure that, during a turn, the inner wheel rotates at a greater angle than the outer wheel. This difference in steering angles allows the wheels to follow curved paths with a common turning center, minimizing tire friction and wear. The turning radius, R, is the distance from the center of the rear axle to the turning center and defines the path that the robot follows during a turn.</p> <p>The steering angles for the inner and outer wheels are calculated as follows:</p> <p> Inner wheel angle (a\u2081): \u00a0\u00a0\u00a0\u00a0\\( a_1 = \\tan^{-1} \\left( \\frac{L}{R - \\frac{T}{2}} \\right) \\)</p> <p> Outer wheel angle (a\u2082): \u00a0\u00a0\u00a0\u00a0\\( a_2 = \\tan^{-1} \\left( \\frac{L}{R + \\frac{T}{2}} \\right) \\)</p> <p>Where: - L is the wheelbase (distance between the front and rear axles), set to 109.15 mm. - T is the track width (distance between the two front wheels), set to 133 mm. - R is the desired turning radius, set to 500 mm (50 cm).</p> <p>Using these values, we calculate the required angles to achieve the minimum turning radius of 50 cm:</p> <ul> <li>Inner wheel angle (a\u2081): 14.13\u00b0</li> <li>Outer wheel angle (a\u2082): 10.91\u00b0</li> </ul>"},{"location":"otherfile/SteeringSystem/#range-of-steering-angles","title":"Range of Steering Angles","text":"<p>To ensure optimal turning capability, the steering system should be capable of adjusting between these angles, providing a range of approximately 10.91\u00b0 to 14.13\u00b0. This range allows for precise control of the robot's turning behavior within the specified turning radius, optimizing maneuverability and stability.</p> <p> </p>"},{"location":"otherfile/Strategy/","title":"Robot Strategy for WRO Future Engineers","text":"<p>In this competition, our robot needs to figure out where to go and how to avoid obstacles using sensors like LiDAR and a camera. Here\u2019s how it works:</p>"},{"location":"otherfile/Strategy/#1-understanding-the-zones","title":"1. Understanding the Zones","text":"<ul> <li>There are special shapes on the board: two X-shapes and four T-shapes. These are called Zones.</li> <li>Our robot uses 4 sensors to find out where these Zones are.</li> <li>After that, the robot locates itself based on these zones and gets ready to move!</li> </ul>"},{"location":"otherfile/Strategy/#_1","title":"Strategy","text":""},{"location":"otherfile/Strategy/#2-looking-for-obstacles","title":"2. Looking for Obstacles","text":"<ul> <li>There are 24 possible places where obstacles could be. We call them P1, P2, P3, \u2026 up to P24.</li> <li>The robot pretends these obstacles are there and checks their actual location using a LiDAR sensor (like a robot eye!).</li> <li>Then it uses a camera to figure out the color of the obstacles:</li> <li>Red = Dangerous</li> <li>Green = Safe</li> <li>None = No obstacle</li> </ul>"},{"location":"otherfile/Strategy/#3-storing-the-information","title":"3. Storing the Information","text":"<ul> <li>Each place, like P1, P2, etc., gets a value:</li> <li>If there\u2019s no obstacle, the value is 0.</li> <li>If there\u2019s a Green obstacle, the value is 1.</li> <li>If there\u2019s a Red obstacle, the value is 2.</li> </ul> <p>For example: <pre><code>P1 = 0 (no obstacle)\nP2 = 2 (red obstacle)\np3 = 1 (green obstacle)\n</code></pre></p>"},{"location":"otherfile/Strategy/#4-finding-the-target","title":"4. Finding the Target","text":"<ul> <li>After knowing where the obstacles are, the robot uses its LiDAR to trace the path to the target.</li> <li>Then it moves carefully to avoid the obstacles and reach its goal!</li> </ul> <p>This is the basic idea of how our robot works in the competition!</p>"},{"location":"schemesfile/schemes/","title":"Schemes","text":"<p>Here\u2019s the updated Markdown documentation, clarifying that all components except the camera and LiDAR are connected to the Arduino Nano, while only the camera and LiDAR are connected to the Raspberry Pi.</p>"},{"location":"schemesfile/schemes/#wro-fe-2024-mindcraft-international-robot-circuit-documentation","title":"WRO-FE 2024 Mindcraft International Robot Circuit Documentation","text":"<p>This document provides a comprehensive overview of the robot circuit used for the World Robot Olympiad (WRO) Future Engineers 2024 competition. The circuit includes various components such as the Raspberry Pi, Arduino Nano, L298N motor driver, sensors, and power management elements. This guide covers the wiring, communication protocols, and component roles within the system.</p> <p></p>"},{"location":"schemesfile/schemes/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Components</li> <li>Power Management</li> <li>7806 Voltage Regulator with Capacitors</li> <li>Buck Converter</li> <li>Communication Protocols</li> <li>I2C Communication</li> <li>USB Serial Communication</li> <li>UART Communication (TX/RX)</li> <li>PWM Signals</li> <li>Component Connections</li> <li>System Architecture and Data Flow</li> </ul>"},{"location":"schemesfile/schemes/#components","title":"Components","text":"<p>The primary components in the circuit include:</p> <ol> <li>Raspberry Pi: Main control and processing unit.</li> <li>Arduino Nano: Microcontroller handling low-level sensor operations and communication with the Raspberry Pi.</li> <li>L298N Motor Driver: Controls a 12V DC motor with magnetic encoders.</li> <li>12V DC Motor with Magnetic Encoders: Drives the robot\u2019s wheels, with encoder feedback for precise control.</li> <li>LiPo Battery (3S, 50C, 2.2Ah, 11.1V): High-capacity power source for the entire system.</li> <li>7806 Voltage Regulator: Provides a stable 6V output for the servo motor.</li> <li>Two 470 \u00b5F Capacitors: Connected to the 7806 for voltage stabilization and filtering.</li> <li>Buck Converter (11.1V to 5V): Supplies 5V power to the Raspberry Pi.</li> <li>DTOF (Distance Time-of-Flight) Sensors (I2C): Measures distances to obstacles.</li> <li>MPU6050 (Gyroscope/Accelerometer): Measures orientation and motion.</li> <li>Servo Motor: Controls small actuators or sensor positioning.</li> <li>Buzzer: Provides audio feedback.</li> <li>Camera Module: Provides video input for image processing.</li> <li>LiDAR Sensor: High-precision distance measurement for mapping or navigation.</li> <li>Switches: Controls power delivery to different components manually.</li> </ol>"},{"location":"schemesfile/schemes/#power-management","title":"Power Management","text":""},{"location":"schemesfile/schemes/#7806-voltage-regulator-with-capacitors","title":"7806 Voltage Regulator with Capacitors","text":"<p>The 7806 voltage regulator is used to convert the LiPo battery voltage (11.1V) to a stable 6V output, powering the servo motor.</p> <ul> <li>Input: Connected to the 11.1V LiPo battery output.</li> <li>Output: Provides 6V for the servo motor.</li> <li>Capacitors for Stabilization and Filtering:</li> <li>Two 470 \u00b5F Capacitors are connected to the 7806 voltage regulator to help stabilize the output voltage and filter out any noise. One capacitor is placed across the input and ground, and the other across the output and ground.</li> <li>Grounding: The 7806 ground pin connects to the shared ground of the entire circuit.</li> </ul>"},{"location":"schemesfile/schemes/#buck-converter-111v-to-5v","title":"Buck Converter (11.1V to 5V)","text":"<p>A buck converter steps down the 11.1V from the LiPo battery to a stable 5V to supply power to the Raspberry Pi.</p> <ul> <li>Input: Connected to the 11.1V LiPo battery.</li> <li>Output: Provides 5V power to the Raspberry Pi.</li> <li>Grounding: Connected to the common ground of the circuit.</li> </ul>"},{"location":"schemesfile/schemes/#communication-protocols","title":"Communication Protocols","text":""},{"location":"schemesfile/schemes/#i2c-communication","title":"I2C Communication","text":"<p>The I2C protocol is used to connect multiple sensors to the same bus, allowing communication with the Arduino Nano through two main lines: SCL (Clock) and SDA (Data). Each sensor has a unique address on the bus.</p> <ul> <li>Components using I2C:</li> <li>DTOF Sensors: Four Time-of-Flight sensors for obstacle detection, each with a unique I2C address.</li> <li>MPU6050: Provides data on orientation and movement.</li> <li>Wiring:</li> <li>SCL (Clock): Shared by all I2C devices, connected to the SCL pin on the Arduino.</li> <li>SDA (Data): Shared by all I2C devices, connected to the SDA pin on the Arduino.</li> </ul>"},{"location":"schemesfile/schemes/#usb-serial-communication","title":"USB Serial Communication","text":"<p>USB Serial Communication is used for direct data transfer between the Raspberry Pi and Arduino Nano.</p> <ul> <li>The USB cable connects the Raspberry Pi and Arduino Nano, enabling bidirectional data transfer.</li> </ul>"},{"location":"schemesfile/schemes/#uart-communication-txrx","title":"UART Communication (TX/RX)","text":"<p>UART (Universal Asynchronous Receiver/Transmitter) is used for communication between the LiDAR sensor and Raspberry Pi.</p> <ul> <li>Wiring:</li> <li>TX (Transmit) on the LiDAR to RX (Receive) on the Raspberry Pi.</li> <li>RX (Receive) on the LiDAR to TX (Transmit) on the Raspberry Pi.</li> </ul>"},{"location":"schemesfile/schemes/#pwm-signals","title":"PWM Signals","text":"<p>PWM (Pulse Width Modulation) signals are used to control both the motor driver and servo.</p> <ul> <li>Motor Driver (L298N): Receives PWM signals from the Arduino Nano to adjust the speed of the 12V DC motor.</li> <li>Servo Motor: Controlled by the Arduino Nano using PWM for precise angle positioning.</li> </ul>"},{"location":"schemesfile/schemes/#component-connections","title":"Component Connections","text":"<p>All components, except the camera and LiDAR, are connected to the Arduino Nano. This includes the motor driver, DTOF sensors, MPU6050, servo motor, and buzzer. The Raspberry Pi is only connected to the camera module (via the CSI port) and LiDAR sensor (via UART TX/RX), handling high-level processing and vision tasks.</p>"},{"location":"schemesfile/schemes/#raspberry-pi","title":"Raspberry Pi","text":"<ul> <li>GPIO:</li> <li>Communicates with the Arduino Nano via USB Serial.</li> <li>Communicates with the LiDAR sensor via UART (TX/RX).</li> <li>Powers the camera module for real-time image processing through the CSI port.</li> </ul>"},{"location":"schemesfile/schemes/#arduino-nano","title":"Arduino Nano","text":"<ul> <li>I2C Bus: Connects to the MPU6050 and Time-of-Flight distance sensors.</li> <li>PWM:</li> <li>Controls the servo motor for actuation.</li> <li>Drives the buzzer for audio signals.</li> <li>GPIO for Motor Control:</li> <li>Connected to the L298N motor driver to control the 12V DC motor with PWM signals.</li> </ul>"},{"location":"schemesfile/schemes/#system-architecture-and-data-flow","title":"System Architecture and Data Flow","text":"<ol> <li>Power Supply:</li> <li>The LiPo battery (11.1V, 3S, 50C, 2.2Ah) provides power to high-current components like the motor driver and motor.</li> <li>The 7806 voltage regulator, along with two 470 \u00b5F capacitors, supplies a stable 6V output to the servo motor.</li> <li> <p>The buck converter steps down the battery voltage to 5V to power the Raspberry Pi.</p> </li> <li> <p>Sensor Data Collection:</p> </li> <li>The Arduino Nano collects data from all I2C sensors (MPU6050, DTOF sensors) and controls the motor, servo, and buzzer.</li> <li> <p>The data from these sensors is processed by the Arduino or transmitted to the Raspberry Pi via USB Serial.</p> </li> <li> <p>High-Level Processing:</p> </li> <li>The Raspberry Pi performs high-level tasks such as video processing and complex decision-making.</li> <li>Image data from the camera module is processed using computer vision libraries like OpenCV.</li> <li> <p>The Raspberry Pi receives distance data from the LiDAR sensor for navigation and obstacle avoidance.</p> </li> <li> <p>Control Flow:</p> </li> <li>The Arduino Nano sends PWM signals to the L298N motor driver to control the 12V DC motor.</li> <li>It also controls the servo motor and buzzer based on feedback from sensors.</li> <li> <p>The Raspberry Pi communicates with the Arduino Nano and sends additional commands as needed.</p> </li> <li> <p>Decision Making:</p> </li> <li>Data from the LiDAR, DTOF sensors, and MPU6050 help in obstacle detection and path planning.</li> <li>Based on this information, the Raspberry Pi and Arduino Nano coordinate actions, such as steering the robot or adjusting speed.</li> </ol> <p>This circuit provides a robust foundation for an autonomous robot with sensing, communication, and motor control. By using both the Raspberry Pi and Arduino Nano, the system effectively distributes processing loads, with the Raspberry Pi focused on high-level vision and navigation and the Arduino Nano managing other essential components.</p>"},{"location":"srcfile/Commands/","title":"Setup:","text":""},{"location":"srcfile/Commands/#updating-package","title":"Updating package:","text":"<pre><code>sudo apt-get update\n</code></pre>"},{"location":"srcfile/Commands/#upgrading-package","title":"Upgrading package:","text":"<pre><code>sudo apt-get upgrade\n</code></pre>"},{"location":"srcfile/Commands/#navigating-to-a-specific-file","title":"Navigating to a specific file:","text":"<pre><code>cd path/to/your/file\n</code></pre>"},{"location":"srcfile/Commands/#going-back","title":"Going back:","text":"<pre><code>cd ..\n</code></pre>"},{"location":"srcfile/Commands/#creating-a-new-folder","title":"Creating a new folder:","text":"<pre><code>mkdir new_folder\n</code></pre>"},{"location":"srcfile/Commands/#creating-a-new-file","title":"Creating a new file:","text":"<pre><code>touch file.py\n</code></pre>"},{"location":"srcfile/Commands/#editing-a-file","title":"Editing a file:","text":"<pre><code>vi file.py\n</code></pre>"},{"location":"srcfile/Commands/#remove-a-file","title":"Remove a file:","text":"<pre><code>rm file.py\n</code></pre>"},{"location":"srcfile/Commands/#running-a-python-code","title":"Running a python code:","text":"<pre><code>python file.py\n</code></pre>"},{"location":"srcfile/Commands/#stop-a-python-code","title":"Stop a python code:","text":"<pre><code>Ctrl + C\n</code></pre>"},{"location":"srcfile/Commands/#libraries-installation","title":"Libraries installation:","text":""},{"location":"srcfile/Commands/#installing-python3","title":"Installing python3:","text":"<pre><code>sudo apt install python3\n</code></pre>"},{"location":"srcfile/Commands/#installing-pip3","title":"Installing pip3:","text":"<pre><code>sudo apt install python3-pip\n</code></pre>"},{"location":"srcfile/Commands/#installing-pyserial-package","title":"Installing Pyserial package:","text":"<pre><code>sudo pip3 install pyserial\n</code></pre>"},{"location":"srcfile/Commands/#installing-rplidar-package","title":"Installing rplidar package:","text":"<pre><code>sudo pip3 install rplidar\n</code></pre>"},{"location":"srcfile/Commands/#install-matplotlib-and-numpy","title":"Install matplotlib and numpy:","text":"<pre><code>sudo pip3 install matplotlib\nsudo pip3 install numpy\n\n//these packages are already on the libraries folder\n</code></pre>"},{"location":"srcfile/Commands/#install-opencv-via-apt","title":"Install opencv via apt:","text":"<pre><code>sudo apt install python3-opencv\nsudo apt install libopencv-dev python3-opencv\n</code></pre>"},{"location":"srcfile/Commands/#adding-on-start-run-functionality","title":"Adding on-start run functionality","text":"<pre><code>sudo touch /etc/systemd/system/mything.service\n</code></pre>"},{"location":"srcfile/Commands/#edit-the-code","title":"Edit the code:","text":"<pre><code>// edit the mything.service edit and add this code:\n[Unit]\nDescription=Run Buzzer Script\nAfter=network.target\n\n[Service]\nExecStart=/usr/bin/python3 /home/mindcraft/Desktop/buzzer.py\nRestart=always\nUser=mindcraft\nGroup=mindcraft\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"srcfile/Commands/#start-the-service","title":"Start the service:","text":"<p><pre><code>sudo systemctl enable mything.service\n</code></pre> <pre><code>sudo systemctl start mything.service\n</code></pre></p>"},{"location":"srcfile/Commands/#view-the-service-status","title":"View the service status:","text":"<pre><code>sudo systemctl status mything.service\n</code></pre>"},{"location":"srcfile/Dashboard/","title":"WRO Future Engineers Competition - Robot Dashboard","text":"<p>This project is a Tkinter-based dashboard designed to enhance the WRO Future Engineers Competition robot with a camera preview, HSV color tuning, sensor readings, and temperature monitoring. This documentation includes detailed explanations of each part of the code, along with usage and setup instructions.</p>"},{"location":"srcfile/Dashboard/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Installation</li> <li>Project Structure</li> <li>Code Explanation</li> <li>Imports</li> <li>Camera Configuration</li> <li>HSV Color Tuning</li> <li>Dashboard Layout</li> <li>Temperature Monitoring</li> <li>Run Dashboard</li> <li>How to Run</li> <li>Usage</li> <li>Acknowledgments</li> </ol>"},{"location":"srcfile/Dashboard/#introduction","title":"Introduction","text":"<p>The dashboard provides a real-time interface to monitor and adjust the robot\u2019s camera, view LiDAR data, monitor temperatures, and control color detection. </p>"},{"location":"srcfile/Dashboard/#installation","title":"Installation","text":""},{"location":"srcfile/Dashboard/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/DexterTaha/WRO-FE-2024-Mindcraft-International\ncd WRO-FE-2024-Mindcraft-International\n</code></pre>"},{"location":"srcfile/Dashboard/#step-2-install-required-libraries","title":"Step 2: Install Required Libraries","text":"<p>Install the required Python libraries using pip:</p> <pre><code>pip install tkinter pillow numpy opencv-python\n</code></pre>"},{"location":"srcfile/Dashboard/#step-3-set-up-the-raspberry-pi-camera","title":"Step 3: Set Up the Raspberry Pi Camera","text":"<p>Enable the Raspberry Pi camera:</p> <pre><code>sudo raspi-config\n</code></pre> <p>Go to <code>Interface Options</code> &gt; <code>Camera</code> and enable it.</p>"},{"location":"srcfile/Dashboard/#project-structure","title":"Project Structure","text":"<pre><code>Dashboard/\n\u251c\u2500\u2500 README.md          # Project documentation file\n\u2514\u2500\u2500 Dashboard.py            # Main Python code file for the dashboard\n</code></pre>"},{"location":"srcfile/Dashboard/#code-explanation","title":"Code Explanation","text":""},{"location":"srcfile/Dashboard/#imports","title":"Imports","text":"<p>The initial code imports necessary libraries:</p> <pre><code>import tkinter as tk\nfrom tkinter import ttk\nfrom PIL import Image, ImageTk\nimport numpy as np\nimport cv2\n</code></pre> <p>Tkinter: Used for building the GUI. ttk: Provides themed widgets. PIL: For image handling in Tkinter. NumPy: For efficient array handling. OpenCV: Used for camera operations and color detection.</p>"},{"location":"srcfile/Dashboard/#camera-configuration","title":"Camera Configuration","text":"<p>The camera capture setup uses OpenCV to initialize and process the camera feed:</p> <p><pre><code>cap = cv2.VideoCapture(0)  # 0 is typically the Pi camera\n</code></pre> - <code>cap</code>: The camera object, which streams the video feed. -This feed is displayed on the Tkinter GUI and processed for color detection.</p>"},{"location":"srcfile/Dashboard/#hsv-color-tuning","title":"HSV Color Tuning","text":"<p>To detect specific colors, HSV values are adjusted through sliders:</p> <pre><code>hue_min = tk.IntVar()\nsat_min = tk.IntVar()\nval_min = tk.IntVar()\n# And similar variables for the upper HSV bounds\n</code></pre> <ul> <li>HSV Sliders: The dashboard provides controls for setting <code>hue</code>, <code>saturation</code>, and <code>value</code> ranges for colors to detect.</li> <li>Mask Creation: A mask is created based on HSV values to isolate colors: <pre><code>hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\nmask = cv2.inRange(hsv, (hue_min.get(), sat_min.get(), val_min.get()),\n                   (hue_max.get(), sat_max.get(), val_max.get()))\n</code></pre></li> </ul> <p>Filtered Display: The mask result is displayed in a dedicated area on the dashboard, allowing real-time HSV adjustments.</p>"},{"location":"srcfile/Dashboard/#dashboard-layout","title":"Dashboard Layout","text":"<p>The GUI layout is set up to place each component strategically: <pre><code>root = tk.Tk()\nroot.geometry(\"800x480\")\n</code></pre> - Main Window: Configured for 800x480 resolution to fit the Raspberry Pi screen. - Frames and Widgets: - Camera Preview: Shows the live camera feed. - Map and LiDAR: A placeholder to show the competition map and integrate LiDAR sensor data. - HSV Sliders: Positioned beside the camera for easy color tuning.</p>"},{"location":"srcfile/Dashboard/#temperature-monitoring","title":"Temperature Monitoring","text":"<p>A helper function reads CPU and GPU temperatures: <pre><code>def get_cpu_temp():\n    # Reads CPU temperature\n</code></pre> - Temperature Data: Retrieved from system files to display in real-time on the dashboard.</p>"},{"location":"srcfile/Dashboard/#run-dashboard","title":"Run Dashboard","text":"<p>The main loop runs the dashboard, refreshing the frames:</p> <p><pre><code>while True:\n    ret, frame = cap.read()\n    # Camera and mask display updates\n    root.update_idletasks()\n    root.update()\n</code></pre> - Frame Capture: Updates the camera feed and applies the HSV mask. - Root Loop: Keeps the Tkinter dashboard running, refreshing the interface.</p>"},{"location":"srcfile/Dashboard/#how-to-run","title":"How to Run","text":"<p>1) Open a terminal in the project directory. 2) Run the following command: <pre><code>python main.py\n</code></pre> 3) The Tkinter dashboard should open, displaying the camera feed, map, temperature, and HSV control panel.</p>"},{"location":"srcfile/Dashboard/#usage","title":"Usage","text":""},{"location":"srcfile/Dashboard/#adjusting-hsv-values","title":"Adjusting HSV Values","text":"<p>1) Use the sliders to adjust <code>hue</code>, <code>saturation</code>, and <code>value</code> ranges for detecting specific colors. 2) Observe changes in the masked feed to identify the target color range.</p>"},{"location":"srcfile/Dashboard/#monitoring-sensor-data","title":"Monitoring Sensor Data","text":"<ul> <li>Temperature: View the CPU and GPU temperatures in real-time.</li> </ul>"},{"location":"srcfile/Dashboard/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>OpenCV for image processing.</li> <li>Pillow for handling image rendering in Tkinter.</li> <li>NumPy for matrix operations.</li> </ul>"},{"location":"srcfile/RaspiCommands/","title":"Raspi-Commands","text":""},{"location":"srcfile/RaspiCommands/#setup","title":"Setup:","text":""},{"location":"srcfile/RaspiCommands/#updating-and-upgrading","title":"Updating and Upgrading:","text":"<p><pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get upgrade\n</code></pre></p>"},{"location":"srcfile/RaspiCommands/#navigating-to-a-specific-file","title":"Navigating to a specific file:","text":"<pre><code>cd path/to/your/file\n</code></pre>"},{"location":"srcfile/RaspiCommands/#going-back","title":"Going back:","text":"<pre><code>cd ..\n</code></pre>"},{"location":"srcfile/RaspiCommands/#creating-a-new-folder","title":"Creating a new folder:","text":"<pre><code>mkdir new_folder\n</code></pre>"},{"location":"srcfile/RaspiCommands/#creating-a-new-file","title":"Creating a new file:","text":"<pre><code>touch file.py\n</code></pre>"},{"location":"srcfile/RaspiCommands/#editing-a-file","title":"Editing a file:","text":"<pre><code>vi file.py\n</code></pre>"},{"location":"srcfile/RaspiCommands/#remove-a-file","title":"Remove a file:","text":"<pre><code>rm file.py\n</code></pre>"},{"location":"srcfile/RaspiCommands/#running-a-python-code","title":"Running a python code:","text":"<pre><code>python file.py\n</code></pre>"},{"location":"srcfile/RaspiCommands/#stopping-a-python-code","title":"Stopping a python code:","text":"<pre><code>Ctrl + C\n</code></pre>"},{"location":"srcfile/RaspiCommands/#installing-python3","title":"Installing python3:","text":"<pre><code>sudo apt install python3\n</code></pre>"},{"location":"srcfile/RaspiCommands/#installing-pip","title":"Installing pip:","text":"<pre><code>sudo apt install python3-pip\n</code></pre>"},{"location":"srcfile/RaspiCommands/#installing-libraries","title":"Installing libraries:","text":""},{"location":"srcfile/RaspiCommands/#pyserial","title":"Pyserial:","text":"<pre><code>sudo apt install python3-serial\n</code></pre>"},{"location":"srcfile/RaspiCommands/#rplidar","title":"RpLidar:","text":"<pre><code>pip3 install rplidar\n</code></pre>"},{"location":"srcfile/RaspiCommands/#matplotlib","title":"Matplotlib:","text":"<pre><code>python3 -m pip install matplotlib\n</code></pre>"},{"location":"srcfile/RaspiCommands/#numpy","title":"Numpy:","text":"<pre><code>python3 -m pip install numpy\n</code></pre>"},{"location":"srcfile/RaspiCommands/#opencv","title":"OpenCV:","text":"<pre><code>sudo apt install python3-opencv\n</code></pre>"},{"location":"srcfile/RaspiCommands/#pillow","title":"Pillow:","text":"<p><pre><code>sudo apt install python3-pil\n</code></pre> if you get to any errors, you can use this code: <pre><code>sudo apt install --reinstall python3-pil python3-pil.imagetk\n</code></pre></p>"},{"location":"srcfile/Test/","title":"Color Detection and Contour Analysis with Picamera2 and OpenCV","text":"<p>This project captures frames from a PiCamera, detects red and green colors in real-time, and identifies contours based on color masks. Each detected contour is labeled with its color and area, and the largest contour is highlighted to indicate its distance.</p>"},{"location":"srcfile/Test/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Setup</li> <li>Code Explanation<ul> <li>initialize_camera</li> <li>capture_frame</li> <li>convert_to_hsv</li> <li>create_color_masks</li> <li>find_and_store_contours</li> <li>draw_and_label_contours</li> <li>main</li> </ul> </li> <li>Running the Code</li> <li>Adjusting Color Detection Ranges</li> <li>Stopping the Program</li> </ol>"},{"location":"srcfile/Test/#setup","title":"Setup","text":"<p>This code requires the following libraries:</p> <pre><code>pip3 install numpy opencv-python picamera2\n</code></pre>"},{"location":"srcfile/Test/#code-explanation","title":"Code Explanation","text":""},{"location":"srcfile/Test/#initialize_camera","title":"initialize_camera","text":"<p><pre><code>def initialize_camera():\n    \"\"\"Initialize and configure the Picamera2.\"\"\"\n    picam2 = Picamera2(camera_num=0)\n    config = picam2.create_preview_configuration()\n    picam2.configure(config)\n    picam2.start()\n    return picam2\n</code></pre> This function initializes the PiCamera by configuring it for real-time preview and starts the camera for capturing frames.</p>"},{"location":"srcfile/Test/#capture_frame","title":"capture_frame","text":"<p><pre><code>def capture_frame(picam2, flip=False, resize_shape=(640, 480)):\n    \"\"\"Capture a frame from the camera, resize, and optionally flip it vertically.\"\"\"\n    frame = picam2.capture_array()\n    frame = cv2.resize(frame, resize_shape)\n    if flip:\n        frame = cv2.flip(frame, 0)  # Flip vertically\n        frame = cv2.flip(frame, 1)  # Flip horizontally\n    return frame\n</code></pre> This function captures a frame, resizes it to the specified shape, and optionally flips it vertically and horizontally.</p>"},{"location":"srcfile/Test/#convert_to_hsv","title":"convert_to_hsv","text":"<p><pre><code>def convert_to_hsv(frame):\n    \"\"\"Convert the frame from BGR to HSV color space.\"\"\"\n    return cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n</code></pre> Converts the frame to HSV color space, which simplifies color segmentation by separating hue, saturation, and value components.</p>"},{"location":"srcfile/Test/#create_color_masks","title":"create_color_masks","text":"<p><pre><code>def create_color_masks(hsv_frame, lower_red, upper_red, lower_green, upper_green):\n    \"\"\"Create color masks for red and green in the HSV frame.\"\"\"\n    mask_red = cv2.inRange(hsv_frame, lower_red, upper_red)\n    mask_green = cv2.inRange(hsv_frame, lower_green, upper_green)\n    return mask_red, mask_green\n</code></pre> This function creates binary masks for red and green colors based on the provided HSV value ranges.</p>"},{"location":"srcfile/Test/#find_and_store_contours","title":"find_and_store_contours","text":"<p><pre><code>def find_and_store_contours(mask, color_label, rectangle_color, label_color):\n    \"\"\"Find and store contours along with their areas for both close and far objects.\"\"\"\n    contours_info = []\n    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n\n    for c in cnts:\n        area = cv2.contourArea(c)\n        if area &gt; 200:  # Lower threshold to capture smaller, distant objects\n            contours_info.append({\n                'contour': c,\n                'area': area,\n                'color_label': color_label,\n                'rectangle_color': rectangle_color,\n                'label_color': label_color\n            })\n    return contours_info\n</code></pre> This function finds contours from each color mask, filters small contours (by area), and stores relevant information such as color label, rectangle color, and label color.</p>"},{"location":"srcfile/Test/#draw_and_label_contours","title":"draw_and_label_contours","text":"<p><pre><code>def draw_and_label_contours(frame, contours_info):\n    \"\"\"Draw and label the contours in the frame based on sorted order by size.\"\"\"\n    contours_info = sorted(contours_info, key=lambda x: x['area'], reverse=True)\n\n    for i, info in enumerate(contours_info):\n        c = info['contour']\n        color_label = info['color_label']\n        rectangle_color = info['rectangle_color']\n        label_color = info['label_color']\n\n        x, y, w, h = cv2.boundingRect(c)\n        cv2.rectangle(frame, (x, y), (x + w, y + h), rectangle_color, 2)\n        cv2.putText(frame, f\"{color_label} {i + 1}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, label_color, 2)\n\n       # Calculate centroid\n        M = cv2.moments(c)\n        if M['m00'] != 0:\n            cX = int(M['m10'] / M['m00'])\n            cY = int(M['m01'] / M['m00'])\n            # Draw the centroid\n            cv2.circle(frame, (cX, cY), 5, rectangle_color, -1)\n            # Draw the vertical line at the Y-coordinate\n            cv2.line(frame, (cX, 0), (cX, frame.shape[0]), rectangle_color, 2)\n            # Display the Y-coordinate\n            cv2.putText(frame, f\"Y: {cY}\", (cX + 10, cY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, rectangle_color, 2)\n\n    return contours_info\n</code></pre> This function draws a bounding box and labels each contour with its color. It calculates the centroid for each contour, draws a marker, and shows the vertical position (Y-coordinate) of the object in the frame.</p>"},{"location":"srcfile/Test/#main","title":"main","text":"<p><pre><code>def main():\n    # Color ranges for red and green (can be adjusted dynamically)\n    lower_red = np.array([97, 170, 70])\n    upper_red = np.array([180, 255, 255])\n    lower_green = np.array([27, 155, 3])\n    upper_green = np.array([75, 255, 255])\n\n    picam2 = initialize_camera()\n\n    while True:\n        frame = capture_frame(picam2, flip=True)  # Vertical flip applied here\n        hsv = convert_to_hsv(frame)\n\n        mask_red, mask_green = create_color_masks(hsv, lower_red, upper_red, lower_green, upper_green)\n\n        # Store red and green contours with their information\n        red_contours_info = find_and_store_contours(mask_red, \"RED\", (0, 0, 255), (0, 0, 255))\n        green_contours_info = find_and_store_contours(mask_green, \"GREEN\", (0, 255, 0), (0, 255, 0))\n\n        # Combine red and green contours into one list\n        all_contours_info = red_contours_info + green_contours_info\n\n        # Draw and label contours with distance order\n        draw_and_label_contours(frame, all_contours_info)\n\n        cv2.imshow(\"FRAME\", frame)\n\n        if cv2.waitKey(1) &amp; 0xFF == 27:  # Exit on 'ESC'\n            break\n\n    picam2.stop()\n    cv2.destroyAllWindows()\n</code></pre> The main function ties everything together:</p> <ol> <li>Defines <code>HSV</code> ranges for red and green.</li> <li>Captures frames, applies color detection, and finds contours.</li> <li>Draws contours and labels them based on proximity (by area).</li> <li>Displays the processed frame in a real-time window.</li> </ol>"},{"location":"srcfile/Test/#running-the-code","title":"Running the Code","text":"<p>To execute this code, simply run:</p> <pre><code>python3 camera.py\n</code></pre>"},{"location":"srcfile/Test/#adjusting-color-detection-ranges","title":"Adjusting Color Detection Ranges","text":"<p>To fine-tune color detection: - Change <code>lower_red</code>, <code>upper_red</code>, <code>lower_green</code>, and <code>upper_green</code> values in the <code>main</code> function for better accuracy under different lighting conditions.</p>"},{"location":"srcfile/Test/#stopping-the-program","title":"Stopping the Program","text":"<p>Press the Ctrl+C key in the display window to stop the program and close the window. <pre><code>Ctrl + C\n</code></pre></p>"},{"location":"srcfile/UbuntuCommands/","title":"Ubuntu-Commands","text":""},{"location":"srcfile/UbuntuCommands/#basic-ubuntu-commands","title":"Basic Ubuntu Commands:","text":"<p>Create a file: <pre><code>touch file.py\n</code></pre> Navigate to a folder: <pre><code>cd folder\n</code></pre> Run a python script: <pre><code>python3 file.py\n</code></pre></p>"},{"location":"srcfile/UbuntuCommands/#preparing-the-ros2-startup-script","title":"Preparing the ROS2 startup script","text":""},{"location":"srcfile/UbuntuCommands/#setup","title":"Setup","text":"<ol> <li>Create a startup script: <pre><code>touch startup.sh\n</code></pre></li> <li>Modify the content: <pre><code>#!/bin/bash\n\n# Source ROS 2 and workspace environment\nsource /opt/ros/humble/setup.bash\nsource ~/ros2_ws/install/setup.bash\n\n# Start RViz in the background\nros2 launch sllidar_ros2 view_sllidar_c1_launch.py &amp;\n\n# Wait for RViz to initialize\nsleep 5\n\n# Start Wall Follower Node\ncd ~/ros2_ws\nros2 run wall_follower wall_follower\n</code></pre></li> <li>Make the script executable: <pre><code>chmod +x /home/mindcraft/start_ros2.sh\n</code></pre></li> </ol>"},{"location":"srcfile/UbuntuCommands/#making-the-script-executable","title":"Making the script executable","text":"<ol> <li>Edit Contrab: <pre><code>crontab -e\n</code></pre></li> <li>Add the following line: <pre><code>@reboot /bin/bash /home/mindcraft/start_ros2.sh &gt; /home/mindcraft/start_ros2.log 2&gt;&amp;1\n</code></pre></li> </ol>"},{"location":"srcfile/UbuntuCommands/#testing-the-setup","title":"Testing the setup","text":"<ol> <li>Reboot the system: <pre><code>sudo reboot\n</code></pre></li> <li>Check the Log File After Reboot: <pre><code>cat /home/mindcraft/start_ros2.log\n</code></pre></li> </ol>"},{"location":"srcfile/arduinofunctions/","title":"Arduino Robot Control Code Documentation","text":"<p>This README provides a detailed explanation of the Arduino code used to control a robot equipped with distance sensors, a steering mechanism, and communication with a Raspberry Pi. The code manages motor control, steering, sensor data acquisition, and communication between the Arduino and Raspberry Pi.</p>"},{"location":"srcfile/arduinofunctions/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Hardware Components</li> <li>Pin Configuration</li> <li>Library Dependencies</li> <li>Code Structure</li> <li>Functions Explanation<ul> <li>Interrupt Service Routines (ISRs)</li> <li>Encoder Functions</li> <li>Motor Control Functions</li> <li>Sensor Setup and Reading Functions</li> <li>Buzzer Functions</li> <li>Communication Functions</li> <li>Utility Functions</li> </ul> </li> <li>Setup and Initialization</li> <li>Main Loop Execution</li> <li>Wiring Diagram</li> <li>How to Use</li> <li>Troubleshooting</li> <li>License</li> </ol>"},{"location":"srcfile/arduinofunctions/#overview","title":"Overview","text":"<p>The provided Arduino code is designed to control a robot with the following features:</p> <ul> <li>Motor Control: Controls the speed and direction of the robot using an L298N motor driver.</li> <li>Steering Mechanism: Uses a servo motor for steering control.</li> <li>Distance Sensing: Utilizes four VL53L1X distance sensors for obstacle detection in all directions (front, back, left, right).</li> <li>Encoder Feedback: Reads encoder data to monitor motor speed and distance traveled.</li> <li>Communication: Exchanges data with a Raspberry Pi for higher-level processing and decision-making.</li> <li>Buzzer Alerts: Provides audible feedback for different robot states (start, stop, error).</li> </ul>"},{"location":"srcfile/arduinofunctions/#hardware-components","title":"Hardware Components","text":"<ul> <li>Arduino Uno (or compatible microcontroller)</li> <li>L298N Motor Driver</li> <li>DC Motor with encoder</li> <li>Servo Motor for steering (connected to pin 10)</li> <li>VL53L1X Distance Sensors (x4) for front, back, left, and right detection</li> <li>Buzzer (connected to pin 8)</li> <li>Switch (connected to analog pin A0)</li> <li>Raspberry Pi 4 Model B (for data processing and control commands)</li> <li>Miscellaneous: Resistors, wires, breadboard or PCB, connectors</li> </ul>"},{"location":"srcfile/arduinofunctions/#pin-configuration","title":"Pin Configuration","text":"Component Arduino Pin L298N EN_A (Speed) 11 L298N IN1 (Direction) 13 L298N IN2 (Direction) 12 Steering Servo 10 Encoder Channel A 2 Encoder Channel B 3 Buzzer 8 Switch A0 VL53L1X XSHUT Pins 4, 5, 6, 7 Gyroscope (example) A2"},{"location":"srcfile/arduinofunctions/#library-dependencies","title":"Library Dependencies","text":"<p>Ensure you have the following libraries installed in your Arduino IDE:</p> <ul> <li>Servo.h: For controlling the servo motor.</li> <li>VL53L1X.h: For interfacing with the VL53L1X distance sensors.</li> <li>Wire.h: For I2C communication with sensors.</li> </ul>"},{"location":"srcfile/arduinofunctions/#code-structure","title":"Code Structure","text":"<p>The code is organized into several sections:</p> <ol> <li>Variable and Constant Definitions: Pin assignments, sensor configurations, and control variables.</li> <li>Interrupt Service Routines (ISRs): Functions to handle encoder pulses.</li> <li>Initialization Functions: Setup functions for the encoder, sensors, and initial states.</li> <li>Motor Control Functions: Functions to control motor speed and direction.</li> <li>Sensor Functions: Functions to read data from the VL53L1X sensors.</li> <li>Buzzer Functions: Functions to produce different sounds for various robot states.</li> <li>Communication Functions: Functions to send data to and receive commands from the Raspberry Pi.</li> <li>Main Loop: The <code>loop()</code> function that runs continuously, handling the robot's operation based on the switch state.</li> </ol>"},{"location":"srcfile/arduinofunctions/#functions-explanation","title":"Functions Explanation","text":""},{"location":"srcfile/arduinofunctions/#interrupt-service-routines-isrs","title":"Interrupt Service Routines (ISRs)","text":"<ul> <li>encoderISR_A(): Increments the encoder count when a pulse is detected on Channel A.</li> <li>encoderISR_B(): Decrements the encoder count when a pulse is detected on Channel B (if using quadrature encoding).</li> </ul>"},{"location":"srcfile/arduinofunctions/#encoder-functions","title":"Encoder Functions","text":"<ul> <li>setupEncoder(): Initializes the encoder pins and attaches the ISRs.</li> <li>readEncoder(): Returns the current encoder count.</li> <li>resetEncoder(): Resets the encoder count to zero.</li> </ul>"},{"location":"srcfile/arduinofunctions/#motor-control-functions","title":"Motor Control Functions","text":"<ul> <li>driveDistanceSpeed(float distanceCM, int speedInput): Moves the robot a specified distance in centimeters at a given speed percentage (-100 to 100). It uses encoder feedback to determine when the desired distance has been traveled.</li> <li>controlRobot(int speedInput, int steeringInput): Controls the robot's speed and steering based on inputs received (e.g., from the Raspberry Pi). Speed input ranges from -100 (full reverse) to 100 (full forward). Steering input ranges from -100 (full left) to 100 (full right).</li> <li>StopMotors(): Stops the motor by setting the control pins to LOW and speed to zero.</li> <li>HoldMotors(): Engages both motor control pins to HIGH to hold the motor position (dynamic braking).</li> </ul>"},{"location":"srcfile/arduinofunctions/#sensor-setup-and-reading-functions","title":"Sensor Setup and Reading Functions","text":"<ul> <li>setupSensors(): Initializes the VL53L1X distance sensors by configuring their XSHUT pins and setting unique I2C addresses.</li> <li>readAndPrintDistances(): Reads distances from all sensors and prints them to the Serial monitor.</li> </ul>"},{"location":"srcfile/arduinofunctions/#buzzer-functions","title":"Buzzer Functions","text":"<ul> <li>BuzzerRobotStart(): Plays a startup sound when the robot is powered on or initialized.</li> <li>BuzzerRobotEnd(): Plays a shutdown sound when the robot operation ends.</li> <li>BuzzerRobotError(): Plays an error sound when an issue is detected (e.g., switch is off).</li> <li>BuzzerRobotSpecial(): Plays a special melody (optional use).</li> </ul>"},{"location":"srcfile/arduinofunctions/#communication-functions","title":"Communication Functions","text":"<ul> <li>sendDataToPi(): Sends sensor readings and motor speed data to the Raspberry Pi via Serial communication.</li> <li>receiveDataFromPi(): Receives control commands from the Raspberry Pi and parses them to control the robot.</li> </ul>"},{"location":"srcfile/arduinofunctions/#utility-functions","title":"Utility Functions","text":"<ul> <li>isSwitchOn(int value): Determines if the switch is in the \"on\" position based on the analog reading.</li> <li>act(): Performs the main actions of sending data to and receiving commands from the Raspberry Pi.</li> </ul>"},{"location":"srcfile/arduinofunctions/#setup-and-initialization","title":"Setup and Initialization","text":"<ol> <li>Serial Communication: Begins Serial communication at 115200 baud rate for communication with the Raspberry Pi.</li> <li>I2C Communication: Initializes the I2C bus for communication with the distance sensors.</li> <li>Pin Modes: Sets the appropriate pin modes for motor control, buzzer, and switch.</li> <li>Servo Initialization: Attaches the steering servo to the designated pin.</li> <li>Motor and Encoder Initialization: Ensures motors are stopped and encoders are set up.</li> <li>Sensor Initialization: Calls <code>setupSensors()</code> to initialize all distance sensors.</li> <li>Startup Sound: Plays the startup sound using <code>BuzzerRobotStart()</code>.</li> </ol>"},{"location":"srcfile/arduinofunctions/#main-loop-execution","title":"Main Loop Execution","text":"<p>The <code>loop()</code> function continuously performs the following steps:</p> <ol> <li>Switch State Check: Reads the switch value to determine if the robot should operate.</li> <li>Operation Execution:</li> <li>If the switch is on (<code>isSwitchOn(switchValue)</code> returns <code>true</code>), it calls the <code>act()</code> function to handle communication and control.</li> <li>If the switch is off, it stops the motors (<code>HoldMotors()</code>) and plays an error sound (<code>BuzzerRobotError()</code>).</li> </ol>"},{"location":"srcfile/arduinofunctions/#wiring-diagram","title":"Wiring Diagram","text":"<p>Note: Please refer to the pin configuration section and ensure all components are connected according to the assigned pins. A wiring diagram would typically be provided here, but since this is a text-based format, please ensure:</p> <ul> <li>Motors: Connected to the L298N motor driver, which is then connected to the Arduino pins <code>ENA</code>, <code>IN_1</code>, and <code>IN_2</code>.</li> <li>Encoder: Encoder channels A and B connected to pins <code>2</code> and <code>3</code>.</li> <li>Servo Motor: Signal wire connected to pin <code>10</code>.</li> <li>VL53L1X Sensors: Each sensor's XSHUT pin connected to pins <code>4</code>, <code>5</code>, <code>6</code>, and <code>7</code>. SDA and SCL connected to Arduino's SDA and SCL pins.</li> <li>Buzzer: Positive pin connected to pin <code>8</code>, negative pin connected to ground.</li> <li>Switch: One side connected to analog pin <code>A0</code>, the other side connected to <code>5V</code>, with a pull-down resistor connected to ground if necessary.</li> <li>Raspberry Pi: Connected via Serial communication to the Arduino (ensure voltage levels are compatible or use a logic level converter).</li> </ul>"},{"location":"srcfile/arduinofunctions/#how-to-use","title":"How to Use","text":"<ol> <li>Hardware Setup: Assemble the robot according to the wiring diagram and ensure all connections are secure.</li> <li>Library Installation: Install all required libraries in the Arduino IDE.</li> <li>Upload Code: Load the provided code into the Arduino IDE and upload it to the Arduino board.</li> <li>Power On: Turn on the robot. The startup sound should play.</li> <li>Switch Activation: Flip the switch connected to pin <code>A0</code> to the \"on\" position to enable robot operation.</li> <li>Raspberry Pi Connection: Ensure the Raspberry Pi is connected and running the appropriate code to send control commands and receive sensor data.</li> <li>Operation: The robot will begin operating based on commands from the Raspberry Pi, moving, steering, and avoiding obstacles as programmed.</li> </ol>"},{"location":"srcfile/arduinofunctions/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No Movement: If the robot doesn't move, check motor connections and ensure the motor driver is properly connected.</li> <li>Sensors Not Responding: Verify the connections of the VL53L1X sensors and ensure their addresses are correctly set.</li> <li>Buzzer Not Sounding: Check the buzzer connections and ensure it is connected to the correct pin.</li> <li>Serial Communication Issues: Ensure the baud rate matches on both the Arduino and Raspberry Pi. Check connections.</li> <li>Switch Not Working: Verify the switch is correctly connected and functioning. Use a multimeter to test continuity.</li> </ul>"},{"location":"srcfile/arduinofunctions/#license","title":"License","text":"<p>This project is open-source and free to use under the MIT License.</p> <p>Note: Always ensure safety when operating robots. Keep clear of moving parts, and disconnect power when making adjustments or modifications.</p>"},{"location":"srcfile/src/","title":"WRO Future Engineers Robot Project Documentation","text":""},{"location":"srcfile/src/#project-overview","title":"Project Overview","text":"<p>This project involves a robot that detects colors via a camera connected to a Raspberry Pi, processes the data, and sends control signals to an Arduino which drives the motors. A dashboard on the Raspberry Pi previews the state of the robot\u2019s components, allowing real-time monitoring and control.</p>"},{"location":"srcfile/src/#hardware-setup","title":"Hardware Setup","text":""},{"location":"srcfile/src/#arduino-connections","title":"Arduino Connections","text":"Component Arduino Pin Motor Speed Control ENA (Pin 11) Motor Direction 1 IN_1 (Pin 13) Motor Direction 2 IN_2 (Pin 12) Steering Servo Pin 10 Encoder A Pin 2 (Interrupt Pin) Encoder B Pin 3 (Interrupt Pin) Buzzer Pin 8 Switch Pin A0 VL53L1X Sensors XSHUT Pins (Pins 4, 5, 6, 7) <pre><code>#define ENA  11                \n#define IN_1  13               \n#define IN_2  12       \n#define buzzerPin  8      \n#define STEERING_SERVO_PIN 10 \n#define ENCODER_PIN_A 2       \n#define ENCODER_PIN_B 3   \n#define switchPin  A0        \n#define xshutPins[sensorCount] = { 4, 5, 6, 7 };\n</code></pre> <p>Note: Ensure that the VL53L1X sensors are correctly wired for I2C communication, and each sensor is assigned a unique address in the <code>setupSensors()</code> function.</p>"},{"location":"srcfile/src/#raspberry-pi-connections","title":"Raspberry Pi Connections","text":"<p>The Raspberry Pi is connected to the Arduino via USB or direct TX/RX serial pins, enabling it to send color detection data to control the robot\u2019s motors. A PS4 controller is used for manual control, where:</p> <ul> <li>Left Joystick: Controls forward/backward movement.</li> <li>Right Joystick: Controls steering.</li> </ul>"},{"location":"srcfile/src/#software-requirements","title":"Software Requirements","text":""},{"location":"srcfile/src/#python-libraries-raspberry-pi","title":"Python Libraries (Raspberry Pi)","text":"<p>Ensure the following Python libraries are installed on the Raspberry Pi:</p> <pre><code>pip3 install numpy tkinter matplotlib pyserial pygame opencv-python\n</code></pre> Library Purpose <code>numpy</code> For numerical operations and array handling <code>tkinter</code> For creating GUI applications <code>matplotlib</code> For plotting data and visualizations <code>pyserial</code> Serial communication between Pi and Arduino <code>pygame</code> For handling joystick input and sound <code>opencv-python</code> Color detection and camera processing <code>RPi.GPIO</code> or <code>gpiozero</code> GPIO control on Raspberry Pi <p>Use <code>pip list</code> to verify installations.</p>"},{"location":"srcfile/src/#arduino-libraries-arduino-ide","title":"Arduino Libraries (Arduino IDE)","text":"<p>In the Arduino IDE, make sure to install the following libraries: 1. Servo - For controlling the steering servo. 2. VL53L1X - For handling ToF distance sensors. 3. Wire - For I2C communication. <pre><code>#include &lt;Servo.h&gt;    \n#include &lt;VL53L1X.h&gt;  \n#include &lt;Wire.h&gt;\n</code></pre></p> <p>To install these libraries: 1. Go to Sketch &gt; Include Library &gt; Manage Libraries\u2026. 2. Search for each library by name and install it.</p>"},{"location":"srcfile/src/#communication-protocol","title":"Communication Protocol","text":""},{"location":"srcfile/src/#serial-communication","title":"Serial Communication","text":"<ul> <li>The Raspberry Pi sends control data (speed and steering) based on color detection.</li> <li>The Arduino receives this data to control motor speed and direction.</li> <li>Arduino sends sensor data (distance, encoder count, etc.) back to the Raspberry Pi for dashboard updates.</li> </ul>"},{"location":"srcfile/src/#data-format","title":"Data Format","text":"<ul> <li>Data Sent to Arduino: <code>speed,steering\\n</code> (e.g., <code>50,20\\n</code>).</li> <li>Data Sent to Raspberry Pi: <code>frontDist,rightDist,leftDist,backDist,gyroZ,encoderSpeed\\n</code> (e.g., <code>100,200,150,300,512,50.5\\n</code>).</li> </ul>"},{"location":"srcfile/src/#arduino-code-highlights","title":"Arduino Code Highlights","text":""},{"location":"srcfile/src/#control-functions","title":"Control Functions","text":"<ol> <li><code>driveDistanceSpeed()</code> - Moves the robot a specified distance at a given speed.</li> <li><code>controlRobot()</code> - Controls motor speed and direction based on received data.</li> <li><code>sendDataToPi()</code> - Sends sensor readings to Raspberry Pi.</li> <li><code>receiveDataFromPi()</code> - Receives control commands from Raspberry Pi.</li> </ol>"},{"location":"srcfile/src/#buzzer-functions","title":"Buzzer Functions","text":"<ul> <li><code>BuzzerRobotStart()</code> - Plays a start-up sound.</li> <li><code>BuzzerRobotEnd()</code> - Plays a shutdown sound.</li> <li><code>BuzzerRobotError()</code> - Indicates errors.</li> <li><code>BuzzerRobotSpecial()</code> - Plays a special tune.</li> </ul>"},{"location":"srcfile/src/#sensor-functions","title":"Sensor Functions","text":"<ul> <li><code>setupSensors()</code> - Initializes and assigns addresses to each VL53L1X sensor.</li> <li><code>readAndPrintDistances()</code> - Reads and prints distances from each sensor.</li> </ul>"},{"location":"t-photos/t-photos/","title":"t-photos","text":"Mindcraft Engineers Team Pic OUR Team Fun Pic \ud83e\udd26\u200d\u2642\ufe0f <p>Our team's fun moment captured perfectly!</p> team members \ud83d\udc64 NAME DERDEB Salmane TAIDI LAAMIRI TAHA TAIDI LAAMIRI MORTADA \ud83d\uddbc\ufe0f IMAGE \ud83d\udd22 AGE 15 YEARS OLD 19 YEARS OLD 16 YEARS OLD \ud83c\udf93 STUDIES 10th Grade Scientific (French Option) Student Industrial Engineering Student + Automated System Degree 11th Grade Physics and Math (French Option) Student \ud83c\udfaf ROLE Computer Vision and Programming Lead Team Leader, Electrical and Electronics Lead Fabrication and Conception Lead \ud83c\udf10 LANGUAGE <ul> <li>Arabic: Native</li> <li>French: Very Good</li> <li>English: Very Good</li> <li>Turkish: Intermediate</li> </ul> <ul> <li>Arabic: Native</li> <li>French: Very Good</li> <li>English: Very Good</li> </ul> <ul> <li>Arabic: Native</li> <li>French: Good</li> <li>English: Beginner</li> </ul> \ud83d\udee0\ufe0f RESPONSIBILITIES <ul> <li>Lead the development and implementation of computer vision algorithms.</li> <li>Handle general programming, ensuring software works with hardware.</li> <li>Create and edit videos, graphics, and team content.</li> <li>Produce 3D animations using Blender for project visuals.</li> <li>Document work on GitHub and maintain the physical engineering notebook.</li> </ul> <ul> <li>Oversee team tasks and ensure deadlines are met.</li> <li>Facilitate communication between team members.</li> <li>Conduct technical study and oversee engineering of the robot.</li> <li>Design and create the PCB and handle electronics connections.</li> <li>Perform component compatibility calculations.</li> <li>Manage the Bill of Materials (BOM) and component sourcing.</li> <li>Document project progress on GitHub.</li> </ul> <ul> <li>Take measurements for robot components.</li> <li>Design and 3D print components.</li> <li>Lead robot assembly and manage mechanical parts.</li> <li>Test, iterate, and improve design versions.</li> <li>Document work on GitHub.</li> </ul> \ud83d\udee0\ufe0f TOOLS AND SOFTWARE <ul> <li> GitHub</li> <li> HTML</li> <li> CSS</li> <li> SCSS</li> <li> JavaScript</li> <li> React</li> <li> Bootstrap</li> <li> Figma</li> <li> C</li> <li> C++</li> <li> Python</li> <li> Linux</li> <li> Ubuntu</li> <li> Raspberry Pi</li> </ul> <ul> <li> GitHub</li> <li> HTML</li> <li> CSS</li> <li> SCSS</li> <li> JavaScript</li> <li> React</li> <li> Bootstrap</li> <li> Figma</li> <li> C</li> <li> C++</li> <li> Python</li> <li> Linux</li> <li> Ubuntu</li> <li> Raspberry Pi</li> </ul> <ul> <li> GitHub</li> <li> HTML</li> <li> CSS</li> <li> JavaScript</li> <li> Figma</li> <li> Blender</li> <li> Onshape</li> <li> creality print                             <li> <li> <li> <li> <li><li> <li> <li> <li> \ud83d\udc08\u200d\u2b1b GITHUB Profile Salmane Derdeb Taha TAIDI LAAMIRI Mortada TAIDI LAAMIRI"},{"location":"v-photos/v-photos/","title":"v-photos","text":"<p>Isometric View</p> <p>Top View</p> <p>Bottom View</p> <p>Right View</p> <p>Left View</p> <p>Face View</p> <p>Rear View</p> <p>Isometric View</p> <p>Top View</p> <p>Bottom View</p> <p>Right View</p> <p>Left View</p> <p>Face View</p> <p>Rear View</p>"},{"location":"v-photos/real%20images/","title":"Index","text":"<p>Isometric View</p> <p>Top View</p> <p>Bottom View</p> <p>Right View</p> <p>Left View</p> <p>Face View</p> <p>Rear View</p>"}]}